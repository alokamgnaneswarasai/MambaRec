{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "def load_data(file_path):\n",
    "    user_dict = {}\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            user, item = map(int, line.strip().split())\n",
    "            if user not in user_dict:\n",
    "                user_dict[user] = []\n",
    "            user_dict[user].append(item)\n",
    "    return user_dict\n",
    "\n",
    "class RecDataset(Dataset):\n",
    "    def __init__(self, user_dict, num_items, max_seq_length, segment_length):\n",
    "        self.data = []\n",
    "        for user, items in user_dict.items():\n",
    "            # items = items[:-1] #remove the last item as it can be used during evaluation time\n",
    "            if len(items) < 2:\n",
    "                continue\n",
    "            \n",
    "            if len(items)<max_seq_length:\n",
    "                items = [0]*(max_seq_length+1-len(items)) + items\n",
    "                \n",
    "            \n",
    "            seq = items[:max_seq_length+1]  #first max_seq_length items\n",
    "            for i in range(0, len(seq) - 1, segment_length):\n",
    "                segment = seq[i:i+segment_length]\n",
    "                target = seq[i+1:i+1+segment_length]\n",
    "                if len(segment) == segment_length and len(target) == segment_length:\n",
    "                    self.data.append((segment, target))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx][0], dtype=torch.long), torch.tensor(self.data[idx][1], dtype=torch.long)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "embed_dim = 32\n",
    "num_layers = 1\n",
    "num_heads = 8\n",
    "hidden_dim = 32\n",
    "mem_length = 100\n",
    "max_seq_length = 200\n",
    "segment_length = 100\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "\n",
    "# Load data\n",
    "\n",
    "file_path = \"data/ml-1m.txt\"\n",
    "user_dict = load_data(file_path)\n",
    "num_items = max(max(items) for items in user_dict.values()) + 1\n",
    "print(\"Number of users: \", len(user_dict))\n",
    "print(\"Number of items: \", num_items)   \n",
    "train_dataset = RecDataset(user_dict, num_items, max_seq_length, segment_length)\n",
    "\n",
    "print(\"Number of training samples: \", len(train_dataset))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "\n",
    "for segment, target in train_loader:\n",
    "    print(segment.shape)\n",
    "    print(target.shape)\n",
    "    break\n",
    "    \n",
    "# if the last batch is smaller than batch_size, the last batch will be dropped \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from labml.logger import inspect\n",
    "from labml_nn.transformers.mha import MultiHeadAttention\n",
    "\n",
    "\n",
    "from typing import List, Optional\n",
    "def shift_right(x: torch.Tensor):\n",
    "    \"\"\"\n",
    "    This method shifts $i^{th}$ row of a matrix by $i$ columns.\n",
    "\n",
    "    If the input is `[[1, 2 ,3], [4, 5 ,6], [7, 8, 9]]`, the shifted\n",
    "    result would be `[[1, 2 ,3], [0, 4, 5], [6, 0, 7]]`.\n",
    "    *Ideally we should mask out the lower triangle but it's ok for our purpose*.\n",
    "    \"\"\"\n",
    "\n",
    "    # Concatenate a column of zeros\n",
    "    zero_pad = x.new_zeros(x.shape[0], 1, *x.shape[2:])\n",
    "    x_padded = torch.cat([x, zero_pad], dim=1)\n",
    "\n",
    "    # Reshape and remove excess elements from the end\n",
    "    x_padded = x_padded.view(x.shape[1] + 1, x.shape[0], *x.shape[2:])\n",
    "    x = x_padded[:-1].view_as(x)\n",
    "\n",
    "    #\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "class RelativeMultiHeadAttention(MultiHeadAttention):\n",
    "   \n",
    "\n",
    "    def __init__(self, heads: int, d_model: int, dropout_prob: float = 0.1):\n",
    "        # The linear transformations do not need a bias since we\n",
    "        # explicitly include it when calculating scores.\n",
    "        # However having a bias for `value` might make sense.\n",
    "        # print(heads, d_model, dropout_prob)\n",
    "        super().__init__(heads, d_model, dropout_prob, bias=False)\n",
    "        \n",
    "        # Number of relative positions\n",
    "        self.P = 2 ** 12\n",
    "\n",
    "        # Relative positional embeddings for key relative to the query.\n",
    "        # We need $2P$ embeddings because the keys can be before or after the query.\n",
    "        self.key_pos_embeddings = nn.Parameter(torch.zeros((self.P * 2, heads, self.d_k)), requires_grad=True)\n",
    "        # Relative positional embedding bias for key relative to the query.\n",
    "        self.key_pos_bias = nn.Parameter(torch.zeros((self.P * 2, heads)), requires_grad=True)\n",
    "        # Positional embeddings for the query is independent of the position of the query\n",
    "        self.query_pos_bias = nn.Parameter(torch.zeros((heads, self.d_k)), requires_grad=True)\n",
    "\n",
    "    def get_scores(self, query: torch.Tensor, key: torch.Tensor):\n",
    "        \n",
    "\n",
    "        # $\\textcolor{orange}{R_k}$\n",
    "        key_pos_emb = self.key_pos_embeddings[self.P - key.shape[0]:self.P + query.shape[0]]\n",
    "        # $\\textcolor{orange}{S_k}$\n",
    "        key_pos_bias = self.key_pos_bias[self.P - key.shape[0]:self.P + query.shape[0]]\n",
    "        # $\\textcolor{orange}{v^\\top}$\n",
    "        query_pos_bias = self.query_pos_bias[None, None, :, :]\n",
    "\n",
    "        # ${(\\textcolor{lightgreen}{\\mathbf{A + C}})}_{i,j} =\n",
    "        # Q_i^\\top K_j +\n",
    "        # \\textcolor{orange}{v^\\top} K_j$\n",
    "        ac = torch.einsum('ibhd,jbhd->ijbh', query + query_pos_bias, key)\n",
    "        # $\\textcolor{lightgreen}{\\mathbf{B'}_{i,k}} = Q_i^\\top \\textcolor{orange}{R_k}$\n",
    "        b = torch.einsum('ibhd,jhd->ijbh', query, key_pos_emb)\n",
    "        # $\\textcolor{lightgreen}{\\mathbf{D'}_{i,k}} = \\textcolor{orange}{S_k}$\n",
    "        d = key_pos_bias[None, :, None, :]\n",
    "        # Shift the rows of $\\textcolor{lightgreen}{\\mathbf{(B' + D')}_{i,k}}$\n",
    "        # to get $$\\textcolor{lightgreen}{\\mathbf{(B + D)}_{i,j} = \\mathbf{(B' + D')}_{i,i - j}}$$\n",
    "        bd = shift_right(b + d)\n",
    "        # Remove extra positions\n",
    "        bd = bd[:, -key.shape[0]:]\n",
    "\n",
    "      \n",
    "        return ac + bd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerXLLayer(nn.Module):\n",
    "    def __init__(self, d_model: int, self_attn: RelativeMultiHeadAttention, dropout_prob: float):\n",
    "        super().__init__()\n",
    "        self.size = d_model\n",
    "        self.self_attn = self_attn\n",
    "        self.linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.norm_self_attn = nn.LayerNorm(d_model)\n",
    "        self.norm_linear = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mem: Optional[torch.Tensor], mask: torch.Tensor):\n",
    "        z = self.norm_self_attn(x)\n",
    "        if mem is not None:\n",
    "            mem = self.norm_self_attn(mem)\n",
    "            \n",
    "            m_z = torch.cat((mem, z), dim=0)\n",
    "        else:\n",
    "            m_z = z\n",
    "        self_attn = self.self_attn(query=z, key=m_z, value=m_z, mask=mask)\n",
    "        x = x + self.dropout(self_attn)\n",
    "        z = self.norm_linear(x)\n",
    "        linear_out = self.linear(z)\n",
    "        x = x + self.dropout(linear_out)\n",
    "        return x\n",
    "\n",
    "class TransformerXL(nn.Module):\n",
    "    def __init__(self, layer: TransformerXLLayer, n_layers: int):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([layer for _ in range(n_layers)])\n",
    "        self.norm = nn.LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mem: List[torch.Tensor], mask: torch.Tensor):\n",
    "        new_mem = []\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            new_mem.append(x.detach())\n",
    "            m = mem[i] if mem else None\n",
    "            x = layer(x=x, mem=m, mask=mask)\n",
    "        return self.norm(x), new_mem\n",
    "\n",
    "class TransformerXLEncoder(nn.Module):\n",
    "    def __init__(self, num_items, embed_dim, num_layers, num_heads, hidden_dim, mem_length, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_items, embed_dim)\n",
    "        self.mem_length = mem_length\n",
    "        # print(embed_dim)\n",
    "        self.transformer = TransformerXL(\n",
    "            TransformerXLLayer(\n",
    "                d_model=embed_dim,\n",
    "                self_attn=RelativeMultiHeadAttention(num_heads,embed_dim, dropout),\n",
    "                dropout_prob=dropout\n",
    "            ),\n",
    "            n_layers=num_layers\n",
    "        )\n",
    "        self.linear = nn.Linear(embed_dim, num_items)\n",
    "    \n",
    "    def forward(self, x, memory=None):\n",
    "        x = self.embedding(x)  # Shape: (B, S, D)\n",
    "        x = x.permute(1, 0, 2)  # Shape: (S, B, D)\n",
    "        mask = None  # Define mask if needed\n",
    "        output, new_memory = self.transformer(x, memory, mask)\n",
    "        logits = self.linear(output)  # Shape: (S, B, num_items)\n",
    "        return logits.permute(1, 2, 0), new_memory  # Shape: (B, num_items, S)\n",
    "    \n",
    "    \n",
    "#example usage\n",
    "# x = torch.randint(0, num_items, (batch_size, segment_length), dtype=torch.long).to(device)\n",
    "# model = TransformerXLEncoder(num_items, embed_dim, num_layers, num_heads, hidden_dim, mem_length).to(device)\n",
    "# logits, memory = model(x)\n",
    "# print(logits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, criterion, device, num_epochs=10):\n",
    "    model.train()\n",
    "    memory = None  # Initialize memory\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits, memory = model(inputs, memory)  # Pass both sequence & memory\n",
    "            \n",
    "            # print(logits.shape, targets.shape)\n",
    "            loss = criterion(logits, targets)  # Shape: (B, num_items, S)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, user_dict, num_items, max_seq_length, segment_length, device):\n",
    "    model.eval()\n",
    "    NDCG, HR, valid_users = 0.0, 0.0, 0\n",
    "    \n",
    "    for user, items in user_dict.items():\n",
    "        if len(items) < 2:\n",
    "            continue\n",
    "        \n",
    "        seq = items[:max_seq_length]\n",
    "        input_seq = torch.tensor(seq[:-1], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        target = seq[-1]\n",
    "        candidates = [target] + random.sample(set(range(1, num_items)) - set(items), 99)\n",
    "        \n",
    "        memory = None\n",
    "        for i in range(0, len(input_seq[0]), segment_length):\n",
    "            segment = input_seq[:, i:i+segment_length]\n",
    "            logits, memory = model(segment, memory)\n",
    "            \n",
    "        # logits shape is (1, num_items, segment_length)\n",
    "        scores = logits[0, :, -1]\n",
    "        scores = scores[candidates]\n",
    "        # print(scores)\n",
    "        ranked = torch.argsort(scores, descending=True).cpu().numpy()\n",
    "        rank = np.where(ranked == 0)[0][0] + 1\n",
    "        # print(rank)\n",
    "        valid_users += 1\n",
    "        \n",
    "        \n",
    "        HR += int(rank <= 10)\n",
    "        NDCG += 1 / np.log2(rank + 1) if rank <= 10 else 0\n",
    "        \n",
    "        if valid_users % 10 == 0:\n",
    "            print(f\"Validated users: {valid_users}, HR@10: {HR / valid_users:.4f}, NDCG@10: {NDCG / valid_users:.4f}\")\n",
    "    print(f\"HR@10: {HR / valid_users:.4f}, NDCG@10: {NDCG / valid_users:.4f}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerXLEncoder(num_items, embed_dim, num_layers, num_heads, hidden_dim, mem_length).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(model)\n",
    "num_epochs=100\n",
    "train_model(model, train_loader, optimizer, criterion, device, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, user_dict, num_items, max_seq_length, segment_length, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/home/gnaneswaras/.local/lib/python3.8/site-packages/mamba_ssm/ops/selective_scan_interface.py:164: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight,\n",
      "/raid/home/gnaneswaras/.local/lib/python3.8/site-packages/mamba_ssm/ops/selective_scan_interface.py:240: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, dout):\n",
      "/raid/home/gnaneswaras/.local/lib/python3.8/site-packages/mamba_ssm/ops/triton/layer_norm.py:986: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(\n",
      "/raid/home/gnaneswaras/.local/lib/python3.8/site-packages/mamba_ssm/ops/triton/layer_norm.py:1045: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, dout, *args):\n",
      "/raid/home/gnaneswaras/.local/lib/python3.8/site-packages/mamba_ssm/distributed/tensor_parallel.py:26: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, x, weight, bias, process_group=None, sequence_parallel=True):\n",
      "/raid/home/gnaneswaras/.local/lib/python3.8/site-packages/mamba_ssm/distributed/tensor_parallel.py:62: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n",
      "/raid/home/gnaneswaras/.local/lib/python3.8/site-packages/mamba_ssm/ops/triton/ssd_combined.py:758: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, zxbcdt, conv1d_weight, conv1d_bias, dt_bias, A, D, chunk_size, initial_states=None, seq_idx=None, dt_limit=(0.0, float(\"inf\")), return_final_states=False, activation=\"silu\",\n",
      "/raid/home/gnaneswaras/.local/lib/python3.8/site-packages/mamba_ssm/ops/triton/ssd_combined.py:836: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, dout, *args):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from mamba_ssm import Mamba2\n",
    "import torch\n",
    "\n",
    "batch, length, dim = 128, 208, 128\n",
    "x = torch.randn(batch, length, dim).to(\"cuda\")\n",
    "print(x.type())\n",
    "model = Mamba2(\n",
    "    # This module uses roughly 3 * expand * d_model^2 parameters\n",
    "    d_model=dim, # Model dimension d_model\n",
    "    d_state=128,  # SSM state expansion factor, typically 64 or 128\n",
    "    d_conv=4,    # Local convolution width\n",
    "    expand=2,    # Block expansion factor\n",
    "    headdim=32,\n",
    ").to(\"cuda\")\n",
    "y = model(x)\n",
    "assert y.shape == x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: torch.Size([2, 64, 384])\n",
      "Y.shape: torch.Size([2, 64, 384])\n"
     ]
    }
   ],
   "source": [
    "print(f\"X.shape: {x.shape}\")\n",
    "print(f\"Y.shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n"
     ]
    }
   ],
   "source": [
    "expand =2\n",
    "d_model = 32\n",
    "d_state = 16\n",
    "headdim = 8\n",
    "d_inner = (expand *d_model) \n",
    "d_ssm = d_inner\n",
    "nheads = d_ssm // headdim\n",
    "d_in_proj = 2 * d_inner + 2 * d_state + nheads\n",
    "print(d_in_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/home/gnaneswaras/.local/lib/python3.8/site-packages/local_attention/rotary.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n",
      "/raid/home/gnaneswaras/.local/lib/python3.8/site-packages/local_attention/rotary.py:57: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n"
     ]
    }
   ],
   "source": [
    "from local_attention import LocalAttention\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "q = torch.randn( 100, 25600, 12) #(batch, length, dim)\n",
    "k = torch.randn( 100, 25600, 12)\n",
    "v = torch.randn( 100, 25600, 12)\n",
    "q,k,v = q.to(\"cuda:5\"), k.to(\"cuda:5\"), v.to(\"cuda:5\")\n",
    "  # Output shape should be (4, 8, 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0957276821136475\n"
     ]
    }
   ],
   "source": [
    "local_attn = LocalAttention(window_size=4,causal=True).to(\"cuda:5\")\n",
    "t1 = time.time()\n",
    "out = local_attn(q, k, v)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 244.14 GiB. GPU 5 has a total capacity of 31.74 GiB of which 11.37 GiB is free. Process 1572693 has 18.33 GiB memory in use. Process 1733147 has 508.00 MiB memory in use. Including non-PyTorch memory, this process has 1.54 GiB memory in use. Of the allocated memory 1.16 GiB is allocated by PyTorch, and 13.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m self_attn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMultiheadAttention(embed_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m, num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(t2\u001b[38;5;241m-\u001b[39mt1)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py:1275\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1261\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1262\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1263\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1272\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1273\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1275\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py:5525\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5523\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbaddbmm(attn_mask, q_scaled, k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   5524\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 5525\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5526\u001b[0m attn_output_weights \u001b[38;5;241m=\u001b[39m softmax(attn_output_weights, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   5527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dropout_p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 244.14 GiB. GPU 5 has a total capacity of 31.74 GiB of which 11.37 GiB is free. Process 1572693 has 18.33 GiB memory in use. Process 1733147 has 508.00 MiB memory in use. Including non-PyTorch memory, this process has 1.54 GiB memory in use. Of the allocated memory 1.16 GiB is allocated by PyTorch, and 13.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "self_attn = nn.MultiheadAttention(embed_dim=12, num_heads=1,batch_first=True).to(\"cuda:5\")\n",
    "t1 = time.time()\n",
    "out = self_attn(q, k, v)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a dummy model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "class DummyModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim,output_dim):\n",
    "        super(DummyModel, self).__init__()\n",
    "        self.emb = nn.Embedding(input_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for backward pass: 0.0338 seconds\n",
      "Time taken for backward pass: 0.0005 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0006 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0018 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0018 seconds\n",
      "Time taken for backward pass: 0.0006 seconds\n",
      "Epoch 1, Loss: 13.1720\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0019 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0005 seconds\n",
      "Time taken for backward pass: 0.0018 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0007 seconds\n",
      "Time taken for backward pass: 0.0007 seconds\n",
      "Time taken for backward pass: 0.0008 seconds\n",
      "Time taken for backward pass: 0.0009 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0005 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Epoch 2, Loss: 12.4537\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0010 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0018 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Epoch 3, Loss: 11.5427\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0018 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Epoch 4, Loss: 11.2968\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0017 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0018 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0009 seconds\n",
      "Time taken for backward pass: 0.0005 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0028 seconds\n",
      "Time taken for backward pass: 0.0018 seconds\n",
      "Time taken for backward pass: 0.0017 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Epoch 5, Loss: 10.1432\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0020 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Epoch 6, Loss: 9.3227\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0018 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0005 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0018 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Epoch 7, Loss: 9.2132\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0022 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0009 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0005 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0016 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0018 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0005 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Epoch 8, Loss: 8.3337\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0017 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0021 seconds\n",
      "Time taken for backward pass: 0.0019 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Epoch 9, Loss: 7.3194\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0017 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0012 seconds\n",
      "Time taken for backward pass: 0.0020 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Time taken for backward pass: 0.0004 seconds\n",
      "Time taken for backward pass: 0.0008 seconds\n",
      "Time taken for backward pass: 0.0006 seconds\n",
      "Time taken for backward pass: 0.0003 seconds\n",
      "Epoch 10, Loss: 6.3666\n"
     ]
    }
   ],
   "source": [
    "from slender_mamba.ops.Bitembedding import replace_embeddings_in_pytorch_model\n",
    "from slender_mamba.ops.Bitembedding import replace_linears_in_pytorch_model\n",
    "\n",
    "model = DummyModel(341600,128, 341600).to(\"cuda\")\n",
    "\n",
    "# replace_embeddings_in_pytorch_model(model)\n",
    "# replace_linears_in_pytorch_model(model)\n",
    "  \n",
    "# create  a dummy dataloader and train the model\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class DummyDataset(Dataset):\n",
    "    def __init__(self, num_samples, input_dim):\n",
    "        self.data = torch.randint(0, input_dim, (num_samples,), dtype=torch.long)\n",
    "        self.labels = torch.randint(0, 341600, (num_samples,), dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "dataset = DummyDataset(1000, 341600)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "# Training loop\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    for batch_data, batch_labels in dataloader:\n",
    "        batch_data, batch_labels = batch_data.to(\"cuda\"), batch_labels.to(\"cuda\")\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_data)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        t1 = time.time()\n",
    "        loss.backward()\n",
    "        t2 = time.time()\n",
    "        print(f\"Time taken for backward pass: {t2-t1:.4f} seconds\")\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb.bias: torch.Size([25600]), torch.float32\n",
      "emb.embedding.weight: torch.Size([100, 25600]), torch.float32\n",
      "emb.norm.weight: torch.Size([25600]), torch.float32\n",
      "emb.norm.bias: torch.Size([25600]), torch.float32\n",
      "fc.weight: torch.Size([10, 25600]), torch.float32\n",
      "fc.bias: torch.Size([10]), torch.float32\n",
      "fc.norm.weight: torch.Size([25600]), torch.float32\n"
     ]
    }
   ],
   "source": [
    "# show the quantized model weights\n",
    "for name, param in model2.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        print(f\"{name}: {param.data.shape}, {param.data.dtype}\")\n",
    "    else:\n",
    "        print(f\"{name}: {param.data.shape}, {param.data.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before replacement:\n",
      "Sequential(\n",
      "  (0): Linear(in_features=1000, out_features=20, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=20, out_features=30, bias=True)\n",
      ")\n",
      "After replacement:\n",
      "Sequential(\n",
      "  (0): BitLinear(in_features=1000, out_features=20, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): BitLinear(in_features=20, out_features=30, bias=True)\n",
      ") Sequential(\n",
      "  (0): Linear(in_features=1000, out_features=20, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=20, out_features=30, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from bitnet.replace_hf import replace_linears_in_pytorch_model\n",
    "import time\n",
    "# Define a simple model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(1000, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 30),\n",
    ")\n",
    "\n",
    "print(\"Before replacement:\")\n",
    "print(model)\n",
    "import copy\n",
    "# copy the same model to model2 (it should be same as model)\n",
    "model2 = copy.deepcopy(model)\n",
    "# Replace nn.Linear with BitLinear\n",
    "replace_linears_in_pytorch_model(model)\n",
    "print(\"After replacement:\")\n",
    "print(model,model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.2325e-01, -4.1521e-01, -6.9748e-01, -1.0258e+00,  2.8045e+00,\n",
      "          5.8941e-01, -2.0953e-01, -5.4988e-01, -3.0823e-01,  2.6648e-02,\n",
      "         -1.3121e+00,  7.1714e-01,  8.4915e-02, -7.2561e-01,  1.3446e+00,\n",
      "         -2.2578e-01, -3.0475e-01, -6.2674e-01,  2.9525e-01, -1.0642e+00,\n",
      "         -1.3544e+00,  1.5409e+00, -1.5531e+00, -4.1290e-01, -9.1820e-01,\n",
      "         -2.7861e-01, -1.6647e+00, -7.2341e-01,  2.2618e-01, -8.2741e-01,\n",
      "         -1.6484e-01,  6.3733e-01, -6.2417e-01, -4.5772e-01,  2.5027e-01,\n",
      "         -1.1514e+00,  2.8663e+00, -1.0725e+00,  1.1625e-01, -8.3147e-01,\n",
      "          5.6266e-02,  4.2682e-01,  4.0587e-01,  1.3664e+00, -1.1746e+00,\n",
      "         -7.8582e-01, -6.0159e-02, -1.7101e-01, -1.1186e+00, -2.3570e-01,\n",
      "         -1.0381e+00, -7.9028e-01,  3.9542e-01,  8.2938e-01, -2.5864e+00,\n",
      "         -2.0256e+00, -4.7984e-01, -6.8970e-02, -1.6089e+00, -2.0956e+00,\n",
      "          2.4936e-01, -1.6862e+00,  2.4753e-01,  9.0480e-01,  1.3980e+00,\n",
      "         -1.5413e+00, -3.3874e-01, -2.1319e-01,  8.7082e-01, -1.4498e+00,\n",
      "          1.3286e+00, -4.0119e-01, -9.1515e-01,  4.3015e-01,  1.6993e+00,\n",
      "          1.8814e-01,  1.4421e+00,  4.9551e-01, -9.5853e-01,  7.4261e-01,\n",
      "         -1.3738e+00,  6.3970e-01,  1.2947e+00,  5.9811e-01,  1.3276e+00,\n",
      "          7.0299e-01,  1.0965e-01,  4.2857e-01, -6.2804e-01,  1.8313e+00,\n",
      "         -1.4671e+00,  9.5345e-01,  2.2998e+00, -9.5537e-01, -1.6656e+00,\n",
      "          1.7766e+00,  1.2959e+00, -3.3860e-01, -1.3274e-01, -3.9058e-01,\n",
      "          8.4496e-01,  8.9527e-02, -5.9396e-01, -3.4898e-01,  7.9229e-01,\n",
      "          6.6054e-01,  9.9937e-01,  7.8511e-01, -5.6749e-02,  1.7298e-01,\n",
      "         -1.3592e+00,  1.0167e+00, -6.3006e-01, -2.4582e-01, -1.3850e-02,\n",
      "          2.1618e-01,  1.3443e-01, -1.7779e-01,  3.8017e-01,  2.4061e+00,\n",
      "          1.3377e+00, -9.7735e-01, -1.2612e+00, -8.4526e-02,  6.0927e-01,\n",
      "         -4.5608e-01,  1.0339e+00,  1.9002e-01, -1.3154e-01, -1.2758e+00,\n",
      "         -9.8359e-01,  5.2160e-01, -1.6168e-01,  2.3038e+00, -1.0140e+00,\n",
      "          3.1064e-01,  8.5612e-01, -2.2523e-01,  5.9129e-01, -5.3665e-01,\n",
      "         -8.7320e-02,  7.8663e-01, -1.6391e+00, -1.7620e+00, -1.7621e+00,\n",
      "         -5.2699e-01, -2.0800e-01, -4.3590e-01, -1.1802e+00, -1.2743e+00,\n",
      "         -2.8605e+00, -1.7420e-01,  1.2832e+00,  3.7087e-01,  8.0492e-01,\n",
      "         -1.1081e+00,  2.5953e+00, -7.7572e-01, -2.2714e-01, -2.0839e+00,\n",
      "          8.7849e-01, -1.9680e+00,  4.6599e-01, -9.4113e-01,  3.0788e-01,\n",
      "         -4.9576e-01, -8.6332e-01,  8.9397e-01,  1.2859e+00, -3.5408e-01,\n",
      "         -3.1463e-01,  9.8220e-01, -1.7584e+00,  1.8664e+00,  3.6791e-01,\n",
      "          2.9176e-01,  1.2582e+00,  5.1432e-01,  1.2401e+00, -8.6000e-01,\n",
      "         -7.1963e-01, -3.9856e-01,  1.0957e+00,  2.2862e-01, -1.0535e-01,\n",
      "         -1.8786e+00,  4.2231e-01,  1.5843e-01,  2.8862e-01, -1.3372e+00,\n",
      "         -2.5895e-01,  4.1394e-02, -7.1683e-01,  5.7631e-01, -1.9654e+00,\n",
      "          1.2521e-01,  6.9752e-01,  4.5171e-01,  1.5462e+00, -2.4254e+00,\n",
      "          1.8721e+00, -6.1937e-01, -1.5257e+00, -5.5657e-01, -5.6205e-01,\n",
      "         -2.0551e+00,  9.7390e-01,  1.0799e+00,  5.9780e-02,  3.5948e-01,\n",
      "         -4.8139e-01, -9.7674e-01, -2.9824e-01,  7.8760e-01, -1.9711e-01,\n",
      "         -2.5637e-01,  1.8641e-02, -2.3586e-01, -1.5391e+00, -6.7862e-01,\n",
      "         -1.0871e-01,  3.7096e-01, -2.2212e-01, -1.0411e+00,  5.3948e-01,\n",
      "          1.9225e+00, -8.7380e-01,  9.8752e-01, -3.7379e-01,  4.7389e-01,\n",
      "          5.2557e-01,  4.4687e-01,  1.2265e+00,  6.5364e-01,  6.1871e-02,\n",
      "          1.4225e+00,  1.3077e-01, -8.0779e-01, -1.2467e+00, -1.4121e+00,\n",
      "          2.0345e-01,  8.8910e-01, -8.1759e-01, -8.2564e-01, -1.6926e+00,\n",
      "          3.2805e-01,  5.8798e-02,  1.3674e-01,  5.1123e-01,  6.6247e-01,\n",
      "         -9.2782e-01,  3.1741e-01, -1.1084e+00, -4.1528e-01,  8.0883e-01,\n",
      "         -1.1519e+00, -1.4433e+00,  1.5617e+00, -2.2686e+00,  2.1563e+00,\n",
      "          2.6022e+00,  2.1569e-01, -1.3519e+00,  2.0699e-01, -1.6919e-01,\n",
      "         -8.5495e-01,  2.2588e-01,  1.0801e-01, -7.0282e-01,  1.7672e+00,\n",
      "          1.8730e+00, -1.4619e+00,  2.8401e-01,  7.9719e-01,  7.0696e-01,\n",
      "          3.8933e-01,  8.6294e-01, -1.7266e+00, -4.9025e-01,  5.0289e-01,\n",
      "          4.8279e-01, -4.3200e-02, -9.7145e-01, -2.3760e-01,  4.6008e-01,\n",
      "          2.3105e-01,  4.5267e-01,  1.9011e+00,  1.9671e+00,  1.3279e+00,\n",
      "         -6.7574e-02,  8.4170e-01,  4.1213e-01, -2.1261e-01,  2.1616e-02,\n",
      "          1.0117e+00,  4.2032e-01, -3.0974e-01, -2.9178e-01,  1.8559e+00,\n",
      "         -1.9941e-01, -2.1691e-01,  1.2491e+00, -1.2553e+00, -2.4328e-01,\n",
      "          4.3974e-01, -4.9130e-02,  6.8886e-01,  5.6293e-01, -4.5658e-01,\n",
      "          1.2803e+00, -1.0265e-01, -1.6806e+00, -1.5076e+00, -9.8285e-01,\n",
      "         -6.3167e-01,  1.4082e-01, -5.7602e-01,  1.1257e+00,  2.0037e+00,\n",
      "          1.5280e+00, -4.6127e-01, -1.6106e-01,  2.2064e+00, -1.4031e-01,\n",
      "          3.9834e-02, -4.8318e-01,  6.2373e-01,  2.9154e-01,  1.1567e+00,\n",
      "         -1.1049e+00,  6.9390e-01,  5.4368e-01,  1.0536e+00, -2.3386e-01,\n",
      "         -4.1870e-01, -1.5094e+00, -5.2176e-01,  1.1397e+00,  1.6806e-01,\n",
      "          1.1176e-01, -1.9048e-01, -1.1452e+00,  3.1877e-01,  1.0099e+00,\n",
      "          1.4067e+00,  7.7004e-01, -8.6401e-02, -1.0128e+00, -1.8323e-02,\n",
      "          4.6848e-01,  1.1177e+00,  3.2906e-02,  1.1543e-01,  6.7923e-01,\n",
      "         -7.2834e-01, -2.5541e-01, -4.3457e-02,  5.6596e-01, -9.4500e-01,\n",
      "         -1.4679e+00,  3.0535e-01, -1.1986e+00, -9.2237e-01,  7.5501e-01,\n",
      "         -1.5681e+00,  1.7535e+00, -7.9733e-01, -1.9052e+00,  7.8676e-01,\n",
      "          2.9754e-01,  7.3772e-01,  2.9874e+00,  1.5199e+00,  1.6248e-01,\n",
      "          1.4571e+00, -6.0675e-01, -1.6065e+00,  7.1618e-01,  1.7017e-01,\n",
      "         -2.5467e-01, -7.5914e-02,  9.9987e-01,  1.2284e+00, -9.3990e-01,\n",
      "         -9.6120e-01,  2.4258e-01,  9.7460e-01,  1.7869e+00,  2.8565e-01,\n",
      "          9.7232e-01,  6.4820e-01,  2.6586e-01, -1.5685e-02,  4.1721e-01,\n",
      "         -2.9855e-01, -9.0961e-01,  1.3502e-01, -1.2904e+00,  4.3516e-01,\n",
      "         -5.8209e-01, -1.4641e+00,  2.3330e+00, -3.4933e-02, -5.5700e-03,\n",
      "          1.2705e+00, -2.0542e+00,  1.1564e+00,  1.0073e+00, -9.8279e-01,\n",
      "         -4.8118e-01, -1.2009e+00,  8.7984e-01, -2.5223e+00,  1.8620e-01,\n",
      "          1.1401e+00,  3.5796e-01, -6.4064e-01,  1.8391e-01,  7.1397e-01,\n",
      "         -9.4230e-01,  4.2049e-02,  1.3310e+00,  2.9625e-01, -1.9113e-01,\n",
      "          5.3437e-01,  7.3637e-01, -7.8198e-02, -1.6155e-01,  8.9295e-02,\n",
      "         -3.0354e-01,  2.2480e+00, -1.0530e+00, -6.6594e-01,  6.1976e-02,\n",
      "         -1.3430e+00,  1.0868e+00,  1.2504e+00,  3.1890e-01,  4.3406e-01,\n",
      "         -1.2199e+00,  3.7747e-01,  9.2001e-01,  3.9894e-01,  1.5774e+00,\n",
      "         -4.4166e-01,  9.5392e-01,  9.7844e-01, -3.8467e-01,  1.1871e+00,\n",
      "         -6.4437e-01, -1.2299e+00,  5.0729e-01,  3.2772e-01,  1.2669e+00,\n",
      "          3.1167e+00,  6.5582e-01, -1.3163e-01, -7.1966e-01, -1.0908e+00,\n",
      "          1.1354e+00,  3.5681e-01,  4.8190e-01, -3.4938e-01,  8.8058e-01,\n",
      "          4.9815e-01,  8.7412e-02, -5.6957e-01,  1.5947e+00,  4.3174e-01,\n",
      "         -1.0416e-01,  1.8570e+00, -6.3923e-01,  1.4800e+00,  7.4063e-01,\n",
      "          2.1885e-01,  1.7412e+00,  1.0759e+00,  1.1538e+00, -1.4995e+00,\n",
      "          1.1644e+00, -8.1141e-01,  8.2397e-01,  1.5662e-01, -6.8904e-01,\n",
      "         -2.9723e-01, -1.9398e+00, -6.5339e-01, -7.3694e-01, -5.6009e-01,\n",
      "         -8.8136e-01, -3.6620e-01, -4.4119e-01, -2.9827e-02,  1.5489e-01,\n",
      "         -1.5190e-01, -2.5225e+00, -4.2995e-01, -9.4762e-01,  1.4560e+00,\n",
      "         -4.3267e-01,  6.1997e-01,  4.5619e-01, -7.1923e-02, -8.1012e-01,\n",
      "         -1.7258e+00,  4.6291e-01,  6.6542e-01, -2.8099e-01,  1.9011e-01,\n",
      "         -5.7746e-01, -1.5274e-01,  5.1267e-01,  7.5036e-01,  1.6272e-01,\n",
      "          1.6514e+00, -5.4501e-02,  1.7489e-01, -2.0027e+00, -7.5641e-01,\n",
      "         -1.7103e+00,  2.1074e-01, -1.4347e+00,  6.9671e-01,  4.6333e-01,\n",
      "          4.9410e-01, -7.6957e-01,  7.1956e-01,  2.2645e-01,  2.0899e-01,\n",
      "         -4.3508e-01, -2.8467e+00,  4.8133e-01, -3.0887e-01,  1.3684e+00,\n",
      "         -8.3182e-01, -2.2943e-01, -1.5101e+00,  1.4940e-02,  1.8423e+00,\n",
      "         -1.6920e+00,  6.8398e-02, -4.1271e-01,  1.3173e+00,  5.5100e-01,\n",
      "         -1.5862e+00,  5.3762e-02, -8.9368e-01,  6.8148e-01, -4.7087e-01,\n",
      "          1.1665e+00,  8.2292e-01, -2.0163e-01, -1.8284e-01,  1.0247e+00,\n",
      "          5.1713e-01,  1.0060e+00,  5.4865e-01,  1.3648e+00,  2.9778e-01,\n",
      "         -1.3018e+00, -1.3695e+00, -8.4254e-01, -8.6548e-01,  3.0874e-01,\n",
      "          6.5977e-01, -1.7135e+00, -2.3749e+00,  1.3924e+00,  6.1789e-01,\n",
      "          1.5601e+00,  4.3986e-01,  2.2547e+00, -1.2680e+00,  5.4210e-01,\n",
      "         -1.6360e+00, -2.2424e-01,  3.4868e-01,  1.0394e+00,  9.5414e-02,\n",
      "          2.1782e-01,  2.7324e-01,  4.3822e-01, -1.9808e+00,  2.9079e-01,\n",
      "         -7.9237e-02,  1.0611e-01, -7.1431e-01, -4.0539e-01, -1.0441e+00,\n",
      "         -2.0675e-01, -6.7067e-01, -1.5067e+00, -8.8633e-01,  6.7776e-01,\n",
      "         -1.5023e+00, -6.1312e-01,  2.0596e+00,  1.3897e+00, -8.1190e-01,\n",
      "         -4.4680e-01,  8.1605e-01, -1.8008e+00,  5.3465e-01, -1.2266e+00,\n",
      "         -1.4392e+00,  1.5683e+00, -5.5060e-01,  1.0155e+00,  1.3190e+00,\n",
      "         -1.1352e+00,  7.8096e-01,  7.6238e-01, -1.6656e+00,  3.5899e-01,\n",
      "          1.0368e-01, -1.6817e-02, -5.2312e-01,  1.1293e+00, -7.6646e-01,\n",
      "          1.3632e+00, -4.2612e-01, -5.9732e-01,  7.8689e-01,  3.7645e-01,\n",
      "         -8.4367e-01, -3.8192e-01,  4.3551e-01, -5.3497e-01, -6.3631e-01,\n",
      "         -1.4196e+00,  2.0130e-01, -2.5332e-02,  4.8157e-01,  2.4059e-02,\n",
      "         -3.6479e-01,  4.3133e-01,  4.3187e-01,  1.0526e-01,  3.3694e-01,\n",
      "         -6.5729e-01, -5.4769e-01, -4.8397e-01, -6.0059e-01, -1.6393e+00,\n",
      "         -9.8167e-01,  5.0034e-02, -1.3247e+00, -9.5768e-02, -5.1680e-01,\n",
      "         -4.5757e-01, -4.4648e-01, -8.3352e-01, -1.3813e+00, -4.2717e-01,\n",
      "         -2.4085e-01,  8.8748e-01, -9.0402e-01,  2.6785e-01, -4.7110e-02,\n",
      "          2.7608e-01, -1.1790e+00,  1.8608e-01,  9.4841e-01, -7.6650e-01,\n",
      "          2.3375e-01, -1.5833e+00, -2.9683e-01,  1.0925e+00, -2.4094e-01,\n",
      "          4.3447e-01, -8.8741e-01,  1.5642e-01,  1.1794e+00, -2.1426e+00,\n",
      "         -1.0523e+00,  5.9353e-01,  3.6270e-02, -1.0489e+00,  1.5591e-01,\n",
      "         -1.7365e+00, -1.0959e-01, -7.5309e-01, -1.6953e+00, -3.8899e-01,\n",
      "         -1.3093e+00, -6.8076e-01,  1.1872e+00, -1.1507e+00,  1.6125e-01,\n",
      "         -8.1769e-01,  5.3340e-01, -1.8950e+00,  1.3093e+00, -3.3841e-01,\n",
      "         -5.8656e-01,  8.7187e-01,  1.0496e+00, -1.3450e+00, -1.3874e+00,\n",
      "          3.6079e-01,  3.4718e+00, -2.8852e-02, -2.4822e-01,  2.8511e-01,\n",
      "         -1.1606e+00, -3.7709e-01, -1.2109e+00, -1.3152e-01, -7.8096e-01,\n",
      "          6.0317e-01, -1.2454e+00, -6.7617e-01, -6.0285e-01,  1.7495e+00,\n",
      "         -1.3258e+00, -1.2338e+00, -8.1703e-02,  7.4745e-01,  4.7707e-01,\n",
      "         -8.3594e-01,  8.0129e-01,  1.3266e+00, -7.2913e-02,  5.6592e-01,\n",
      "          3.8958e-01, -6.2271e-01,  4.4119e-01, -3.7569e-01,  5.8202e-01,\n",
      "         -2.3127e-01,  8.2873e-01,  1.2399e+00,  1.4373e+00, -5.1538e-01,\n",
      "          9.6270e-01, -2.4688e+00,  2.0112e-03,  7.8073e-01,  5.9447e-02,\n",
      "          6.5316e-01, -5.2667e-02,  1.2913e-01,  1.2467e+00, -1.7658e+00,\n",
      "         -3.4534e-01, -2.8523e-02,  1.7275e+00, -1.6859e+00,  4.6688e-01,\n",
      "          2.2602e-01,  4.1215e-01,  7.2216e-01,  1.7980e+00,  1.2110e+00,\n",
      "         -9.1830e-01,  4.9539e-01, -1.2470e+00,  1.0053e+00,  4.8640e-01,\n",
      "          4.3352e-01, -8.6305e-02,  2.5842e-01,  1.0213e+00,  9.8955e-01,\n",
      "         -1.7689e+00, -6.1975e-01, -2.7009e-01,  7.4462e-01,  9.5102e-01,\n",
      "          1.0252e+00, -3.5503e+00, -1.8024e+00,  1.0520e+00, -6.9586e-01,\n",
      "         -2.0982e-01,  4.2358e-01,  1.1168e+00, -2.6977e-01,  2.2915e-01,\n",
      "         -1.9859e+00,  5.5986e-01,  4.5322e-01,  6.6165e-01,  8.2355e-01,\n",
      "         -1.3140e+00,  3.2518e-01,  6.8641e-01,  3.0449e-01,  1.0512e-02,\n",
      "          8.5193e-01, -1.7439e+00,  4.1328e-01,  9.8110e-01, -7.0982e-01,\n",
      "         -1.5690e+00, -1.8017e-01,  5.0496e-02,  9.4688e-01, -4.1268e-02,\n",
      "         -1.1523e+00,  1.3038e+00, -1.0926e+00, -5.7831e-01, -1.1550e+00,\n",
      "         -9.8724e-02, -2.2045e+00, -6.5334e-01, -1.2966e+00,  6.7005e-01,\n",
      "          1.3348e+00,  1.2511e+00, -4.8304e-01, -2.9823e-01, -1.2403e-01,\n",
      "         -4.3628e-02, -6.4784e-01, -1.4339e+00,  1.2391e+00, -6.0105e-01,\n",
      "          1.4139e+00, -1.1307e+00,  2.0475e-01,  6.7283e-01,  5.9853e-02,\n",
      "         -4.6136e-01,  6.6850e-01, -1.2184e+00,  1.5438e+00,  7.6229e-01,\n",
      "         -6.7615e-01,  1.0272e+00,  3.4016e-01, -2.2376e-01, -7.1889e-01,\n",
      "         -1.5611e+00,  1.9673e+00, -1.2408e+00, -8.4268e-01,  2.4702e-01,\n",
      "          5.1557e-01,  1.3373e+00,  9.4900e-01, -2.1995e-01,  5.4193e-01,\n",
      "          1.0398e+00, -9.0257e-01,  1.4983e+00,  1.0985e+00,  6.7797e-01,\n",
      "         -2.4977e-01,  8.0520e-01, -1.1868e+00, -4.9024e-01, -5.7976e-01,\n",
      "          2.6725e-01,  8.6493e-01,  5.4864e-01,  3.0896e-01,  3.6932e-01,\n",
      "         -1.5996e+00, -8.7625e-01,  3.5335e-01, -1.4844e+00, -1.2489e+00,\n",
      "          5.0370e-01,  7.3130e-01,  1.9253e-02,  4.0288e-01,  6.6493e-01,\n",
      "         -1.0115e+00,  6.4434e-01,  2.5952e-01,  1.5387e+00,  7.1841e-01,\n",
      "         -3.8548e-01, -3.2069e-01, -6.8442e-01,  1.7604e+00,  1.3730e-02,\n",
      "         -2.7236e+00,  8.5686e-02, -9.6789e-01, -1.4677e+00, -5.3778e-01,\n",
      "         -3.2255e-01, -4.6151e-02,  8.0440e-01, -1.4265e+00, -9.4148e-01,\n",
      "          1.7660e-01,  7.0556e-01, -1.2944e+00, -3.7779e-01,  1.0752e+00,\n",
      "         -3.0461e-01,  8.0257e-01,  2.5538e-01,  2.1717e+00,  2.0528e+00,\n",
      "          2.2138e-01, -6.1716e-01, -3.5272e-01, -5.6611e-01, -4.1108e-01,\n",
      "         -2.8367e+00,  6.5507e-01, -1.2824e+00, -6.9134e-01,  7.1606e-01,\n",
      "         -3.1301e-01, -1.3359e+00,  8.1149e-01,  6.2058e-01,  5.9248e-01,\n",
      "         -6.0930e-01,  2.8940e-01,  4.8348e-01,  3.1832e-01, -2.0996e+00,\n",
      "         -4.6261e-01,  1.2317e+00,  5.3638e-01, -3.3305e-01,  1.0387e+00,\n",
      "         -5.9738e-01,  4.7681e-01, -1.3309e+00,  9.7548e-01, -4.9604e-01,\n",
      "         -1.9733e+00,  3.1728e-01, -4.3005e-01, -3.7461e-01, -2.9766e-01,\n",
      "          9.5851e-01, -5.2576e-01, -9.6585e-01,  1.1115e+00,  1.1875e+00,\n",
      "          4.5245e-01, -4.8768e-01,  4.0495e-02, -1.3322e+00,  1.4847e+00,\n",
      "          4.0278e-01, -1.8841e+00,  5.5177e-02, -1.3302e+00, -1.6476e+00,\n",
      "          6.0878e-01, -4.2054e-01,  6.8082e-01,  1.5588e+00,  1.3226e+00,\n",
      "          6.2427e-01,  1.5207e+00,  3.7920e-01, -9.0532e-01, -1.5252e-01,\n",
      "          1.1689e-01,  4.5234e-01, -1.8648e+00, -1.2485e+00,  2.0875e+00,\n",
      "         -1.4517e+00, -7.4364e-01, -2.3235e-01,  1.4028e-01,  1.4340e+00,\n",
      "         -6.4021e-01, -1.2524e-01,  5.5556e-01, -2.3098e-01,  4.5070e-01,\n",
      "         -5.0205e-01,  3.3901e-01,  5.7868e-01,  1.1683e-01, -5.9080e-01,\n",
      "          9.9911e-01, -1.2365e+00, -3.2514e-01, -1.4261e+00,  4.3269e-01,\n",
      "         -1.8390e-01, -8.0548e-01,  7.7536e-01, -5.9542e-01, -3.7051e-01,\n",
      "         -9.0889e-02,  1.3464e+00,  2.2923e-01,  2.8498e-04, -2.7141e+00,\n",
      "         -6.6556e-01, -7.4565e-01, -5.5946e-01, -6.5498e-01,  3.1261e-01]])\n",
      "Time taken: 0.0015854835510253906\n",
      "Output: tensor([[-0.0013, -0.0312, -0.0020,  0.0510, -0.0059, -0.0065, -0.0211, -0.0257,\n",
      "         -0.0453, -0.0499,  0.0187,  0.0464,  0.0059, -0.0233,  0.0246, -0.0453,\n",
      "         -0.0257, -0.0011, -0.0024,  0.0266, -0.0176, -0.0322,  0.0257,  0.0046,\n",
      "         -0.0266, -0.0207,  0.0464,  0.0510,  0.0059,  0.0011]],\n",
      "       grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1000)\n",
    "print(input)\n",
    "t1 = time.time()\n",
    "output = model(input)\n",
    "t2 = time.time()\n",
    "print(\"Time taken:\", t2 - t1)\n",
    "print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.0007174015045166016\n",
      "Output: tensor([[-0.1522,  0.0843, -0.2840,  0.2175,  0.1888,  0.0884, -0.1462, -0.2468,\n",
      "          0.5765,  0.0716, -0.0468, -0.1874,  0.2164, -0.5822, -0.2504, -0.1080,\n",
      "         -0.2837, -0.2074, -0.7073,  0.0811,  0.1376, -0.0893, -0.3422, -0.1727,\n",
      "          0.1800, -0.3411,  0.2276,  0.0574,  0.0556, -0.1227]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "output = model2(input)\n",
    "t2 = time.time()\n",
    "print(\"Time taken:\", t2 - t1)\n",
    "print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           UserId   ProductId  Rating   Timestamp\n",
      "0  A39HTATAQ9V7YF  0205616461     5.0  1369699200\n",
      "1  A3JM6GV9MNOF9X  0558925278     3.0  1355443200\n",
      "2  A1Z513UWSAAO0F  0558925278     5.0  1404691200\n",
      "3  A1WMRR494NWEWV  0733001998     4.0  1382572800\n",
      "4  A3IAAVS479H7M7  0737104473     1.0  1274227200\n"
     ]
    }
   ],
   "source": [
    "# Open the ratings_Beauty.csv file and print the  header\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"ratings_Beauty.csv\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The header is like this UserId   ProductId  Rating   Timestamp\n",
    "\n",
    "# So your task is to create a .txt file where each line is like this:\n",
    "# UserId ProductId with sort on based on timestamp  and map user_id starting from 1 and product_id starting from 1\n",
    "\n",
    "# For example:\n",
    "# 1 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"ratings_Beauty.csv\")\n",
    "df = df.sort_values(by='Timestamp')\n",
    "df = df.reset_index(drop=True)\n",
    "df['UserId'] = df['UserId'].astype('category').cat.codes + 1\n",
    "df['ProductId'] = df['ProductId'].astype('category').cat.codes + 1\n",
    "df = df[['UserId', 'ProductId']]\n",
    "df.to_csv(\"data/ratings_Beauty.txt\", sep=' ', index=False, header=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min user id:  1\n",
      "Max user id:  1210271\n"
     ]
    }
   ],
   "source": [
    "# print min user id and max user id\n",
    "\n",
    "df = pd.read_csv(\"data/ratings_Beauty.txt\", sep=' ', header=None)\n",
    "print(\"Min user id: \", df[0].min())\n",
    "print(\"Max user id: \", df[0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while saving make sure user id is sorted\n",
    "df = df.sort_values(by=0)\n",
    "df.to_csv(\"data/ratings_Beauty.txt\", sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sequence length:  1.6715842980621696\n"
     ]
    }
   ],
   "source": [
    "# print average sequence length for each user\n",
    "user_dict = {}\n",
    "with open(\"data/ratings_Beauty.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        user, item = map(int, line.strip().split())\n",
    "        if user not in user_dict:\n",
    "            user_dict[user] = []\n",
    "        user_dict[user].append(item)\n",
    "avg_seq_len = sum(len(items) for items in user_dict.values()) / len(user_dict)\n",
    "print(\"Average sequence length: \", avg_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
