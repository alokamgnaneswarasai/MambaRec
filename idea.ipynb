{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ddb28ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5ec20d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22530a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 128\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "dropout = 0.1\n",
    "max_seq_length = 200\n",
    "window_size = 20  # Â±50 items around each mask\n",
    "chunk_size = 100  # Approximate chunk size for compression\n",
    "batch_size = 8192\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "mask_prob = 0.15  # Probability of masking an item\n",
    "num_negatives = 99  # For evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b253df08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataset class\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, user_dict, max_seq_length, window_size, mask_prob):\n",
    "        self.user_dict = user_dict\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.window_size = window_size\n",
    "        self.mask_prob = mask_prob\n",
    "        self.users = list(user_dict.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user = self.users[idx]\n",
    "        seq = self.user_dict[user][:self.max_seq_length]\n",
    "        if len(seq) < 2:\n",
    "            seq = [0] * self.max_seq_length  # Pad with zeros if too short\n",
    "        return self.process_sequence(seq)\n",
    "\n",
    "    def process_sequence(self, seq):\n",
    "        # Pad or truncate sequence\n",
    "        seq = seq[:self.max_seq_length]\n",
    "        if len(seq) < self.max_seq_length:\n",
    "            seq = seq + [0] * (self.max_seq_length - len(seq))\n",
    "\n",
    "        # Randomly mask items\n",
    "        mask_positions = []\n",
    "        for i in range(len(seq)):\n",
    "            if seq[i] == 0:  # Skip padding\n",
    "                continue\n",
    "            if random.random() < self.mask_prob:\n",
    "                mask_positions.append(i)\n",
    "                if random.random() < 0.8:\n",
    "                    seq[i] = -1  # [MASK] token (use -1 as placeholder)\n",
    "                elif random.random() < 0.5:\n",
    "                    seq[i] = random.randint(1, num_items)  # Random item\n",
    "                # Else keep original (10% chance)\n",
    "\n",
    "        if not mask_positions:\n",
    "            # Ensure at least one mask\n",
    "            i = random.randint(0, len(seq) - 1)\n",
    "            while seq[i] == 0:\n",
    "                i = random.randint(0, len(seq) - 1)\n",
    "            mask_positions.append(i)\n",
    "            seq[i] = -1\n",
    "\n",
    "        # Dynamic chunking\n",
    "        compressed_seq, chunk_map = self.compress_sequence(seq, mask_positions)\n",
    "        return {\n",
    "            \"seq\": torch.tensor(seq, dtype=torch.long),\n",
    "            \"compressed_seq\": torch.tensor(compressed_seq, dtype=torch.long),\n",
    "            \"mask_positions\": torch.tensor(mask_positions, dtype=torch.long),\n",
    "            \"chunk_map\": chunk_map\n",
    "        }\n",
    "\n",
    "    def compress_sequence(self, seq, mask_positions):\n",
    "        # Create windows around mask positions\n",
    "        windows = []\n",
    "        for pos in sorted(mask_positions):\n",
    "            start = max(0, pos - self.window_size)\n",
    "            end = min(len(seq), pos + self.window_size + 1)\n",
    "            windows.append((start, end))\n",
    "\n",
    "        # Merge overlapping windows\n",
    "        merged = []\n",
    "        current_start, current_end = windows[0]\n",
    "        for start, end in windows[1:]:\n",
    "            if start <= current_end:\n",
    "                current_end = max(current_end, end)\n",
    "            else:\n",
    "                merged.append((current_start, current_end))\n",
    "                current_start, current_end = start, end\n",
    "        merged.append((current_start, current_end))\n",
    "\n",
    "        # Identify gaps and compress\n",
    "        compressed_seq = []\n",
    "        chunk_map = []  # Maps compressed_seq indices to (start, end) or item index\n",
    "        last_end = 0\n",
    "        chunk_id = num_items + 1  # Start chunk IDs after item IDs\n",
    "\n",
    "        for start, end in merged:\n",
    "            # Compress gap before window\n",
    "            if last_end < start:\n",
    "                gap = seq[last_end:start]\n",
    "                compressed_seq.append(chunk_id)\n",
    "                chunk_map.append((last_end, start))\n",
    "                chunk_id += 1\n",
    "            # Add window items\n",
    "            for i in range(start, end):\n",
    "                compressed_seq.append(seq[i])\n",
    "                chunk_map.append(i)\n",
    "            last_end = end\n",
    "\n",
    "        # Compress final gap\n",
    "        if last_end < len(seq):\n",
    "            compressed_seq.append(chunk_id)\n",
    "            chunk_map.append((last_end, len(seq)))\n",
    "\n",
    "        return compressed_seq, chunk_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87aa1387",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialRecommender(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim, num_heads, num_layers, dropout):\n",
    "        super(SequentialRecommender, self).__init__()\n",
    "        self.num_items = num_items\n",
    "        self.embedding = nn.Embedding(num_items + 1000, embedding_dim, padding_idx=0)  # +1000 for chunk IDs\n",
    "        self.mask_embedding = nn.Parameter(torch.randn(embedding_dim))\n",
    "        self.pos_encoding = nn.Parameter(self.create_pos_encoding(5000, embedding_dim))\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=embedding_dim,\n",
    "                nhead=num_heads,\n",
    "                dim_feedforward=embedding_dim * 4,\n",
    "                dropout=dropout,\n",
    "                batch_first=True\n",
    "            ),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(embedding_dim, num_items)\n",
    "\n",
    "    def create_pos_encoding(self, max_len, dim):\n",
    "        pe = torch.zeros(max_len, dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, dim, 2).float() * (-math.log(10000.0) / dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return pe\n",
    "\n",
    "    def compress_chunk(self, chunk, chunk_len):\n",
    "        # Average pooling for chunk compression\n",
    "        chunk_emb = self.embedding(chunk)  # (batch, chunk_len, dim)\n",
    "        chunk_mask = (chunk != 0).float().unsqueeze(-1)  # (batch, chunk_len, 1)\n",
    "        chunk_emb = chunk_emb * chunk_mask\n",
    "        chunk_sum = chunk_emb.sum(dim=1)  # (batch, dim)\n",
    "        chunk_count = chunk_mask.sum(dim=1).clamp(min=1)  # (batch, 1)\n",
    "        return chunk_sum / chunk_count  # (batch, dim)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        seq = batch[\"compressed_seq\"].to(device)  # (batch, compressed_len)\n",
    "        chunk_map = batch[\"chunk_map\"]\n",
    "        mask_positions = batch[\"mask_positions\"].to(device)  # (batch, num_masks)\n",
    "\n",
    "        # Initialize embeddings\n",
    "        batch_size, seq_len = seq.shape\n",
    "        embeddings = torch.zeros(batch_size, seq_len, embedding_dim).to(device)\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            for i in range(seq_len):\n",
    "                item = seq[b, i].item()\n",
    "                if item == -1:  # [MASK]\n",
    "                    embeddings[b, i] = self.mask_embedding\n",
    "                elif item >= self.num_items:  # Chunk\n",
    "                    chunk_start, chunk_end = chunk_map[b][i]\n",
    "                    chunk = batch[\"seq\"][b, chunk_start:chunk_end].unsqueeze(0)\n",
    "                    embeddings[b, i] = self.compress_chunk(chunk, chunk_end - chunk_start)[0]\n",
    "                else:  # Item\n",
    "                    embeddings[b, i] = self.embedding(seq[b, i])\n",
    "\n",
    "        # Add positional encodings\n",
    "        embeddings = embeddings + self.pos_encoding[:seq_len].unsqueeze(0)\n",
    "\n",
    "        # Transformer\n",
    "        mask = (seq == 0).to(device)\n",
    "        output = self.transformer(embeddings, src_key_padding_mask=mask)  # (batch, seq_len, dim)\n",
    "\n",
    "        # Predict items at mask positions\n",
    "        logits = []\n",
    "        for b in range(batch_size):\n",
    "            mask_pos = mask_positions[b]\n",
    "            mask_output = output[b, mask_pos]  # (num_masks, dim)\n",
    "            logit = self.fc(mask_output)  # (num_masks, num_items)\n",
    "            logits.append(logit)\n",
    "        logits = torch.stack(logits)  # (batch, num_masks, num_items)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def predict(self, input_seq):\n",
    "        # For inference: append [NEXT] and compress\n",
    "        seq = input_seq[:, :max_seq_length]\n",
    "        seq = torch.where(seq >= self.num_items, torch.zeros_like(seq), seq)  # Replace invalid items\n",
    "        next_pos = seq.shape[1]\n",
    "        seq = torch.cat([seq, torch.tensor([[-1]], device=seq.device)], dim=1)  # Append [NEXT]\n",
    "\n",
    "        # Compress sequence with [NEXT] as mask\n",
    "        compressed_seqs = []\n",
    "        for b in range(seq.shape[0]):\n",
    "            s = seq[b].cpu().numpy().tolist()\n",
    "            compressed, _ = MovieLensDataset.compress_sequence(\n",
    "                None, s, [next_pos]\n",
    "            )\n",
    "            compressed_seqs.append(compressed)\n",
    "        max_len = max(len(s) for s in compressed_seqs)\n",
    "        compressed_seq = torch.zeros(seq.shape[0], max_len, dtype=torch.long)\n",
    "        for b, s in enumerate(compressed_seqs):\n",
    "            compressed_seq[b, :len(s)] = torch.tensor(s)\n",
    "        compressed_seq = compressed_seq.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        embeddings = torch.zeros(seq.shape[0], max_len, embedding_dim).to(device)\n",
    "        for b in range(seq.shape[0]):\n",
    "            for i in range(len(compressed_seqs[b])):\n",
    "                item = compressed_seq[b, i].item()\n",
    "                if item == -1:  # [NEXT]\n",
    "                    embeddings[b, i] = self.mask_embedding\n",
    "                elif item >= self.num_items:  # Chunk\n",
    "                    chunk_start = i * chunk_size\n",
    "                    chunk_end = min(chunk_start + chunk_size, input_seq.shape[1])\n",
    "                    chunk = input_seq[b, chunk_start:chunk_end].unsqueeze(0)\n",
    "                    embeddings[b, i] = self.compress_chunk(chunk, chunk_end - chunk_start)[0]\n",
    "                else:\n",
    "                    embeddings[b, i] = self.embedding(compressed_seq[b, i])\n",
    "\n",
    "        embeddings = embeddings + self.pos_encoding[:max_len].unsqueeze(0)\n",
    "        mask = (compressed_seq == 0).to(device)\n",
    "        output = self.transformer(embeddings, src_key_padding_mask=mask)\n",
    "        logits = self.fc(output[:, -1])  # Predict at [NEXT]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10c76ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, user_dict, num_items, max_seq_length, device):\n",
    "    model.eval()\n",
    "    NDCG, HR, valid_users = 0.0, 0.0, 0\n",
    "\n",
    "    for user, items in user_dict.items():\n",
    "        if len(items) < 2:\n",
    "            continue\n",
    "\n",
    "        seq = items[:max_seq_length]\n",
    "        input_seq = torch.tensor(seq[:-1], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        target = seq[-1]\n",
    "        candidates = [target] + random.sample(list(set(range(1, num_items + 1)) - set(items)), num_negatives)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model.predict(input_seq)  # (1, num_items)\n",
    "            scores = logits[0, candidates]  # Scores for candidates\n",
    "            ranked = torch.argsort(scores, descending=True).cpu().numpy()\n",
    "            rank = np.where(ranked == 0)[0][0] + 1\n",
    "\n",
    "        valid_users += 1\n",
    "        HR += int(rank <= 10)\n",
    "        NDCG += 1 / np.log2(rank + 1) if rank <= 10 else 0\n",
    "\n",
    "        if valid_users % 100 == 0:\n",
    "            print(f\"Validated users: {valid_users}, HR@10: {HR / valid_users:.4f}, NDCG@10: {NDCG / valid_users:.4f}\")\n",
    "\n",
    "    print(f\"Final HR@10: {HR / valid_users:.4f}, NDCG@10: {NDCG / valid_users:.4f}\")\n",
    "    return HR / valid_users, NDCG / valid_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "924ea007",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and preprocess dataset\n",
    "def load_movielens(file_path):\n",
    "    user_dict = defaultdict(list)\n",
    "    item_set = set()\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            user_id, item_id = map(int, line.strip().split())\n",
    "            user_dict[user_id].append(item_id)\n",
    "            item_set.add(item_id)\n",
    "    num_items = max(item_set)\n",
    "    return user_dict, num_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "826f91cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 6040, Number of items: 3416\n"
     ]
    }
   ],
   "source": [
    "file_path = \"data/ml-1m.txt\"\n",
    "user_dict, num_items = load_movielens(file_path)\n",
    "print(f\"Number of users: {len(user_dict)}, Number of items: {num_items}\")\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = MovieLensDataset(user_dict, max_seq_length, window_size, mask_prob)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bab975b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [50] at entry 0 and [45] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      8\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     10\u001b[0m     seq \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m     logits \u001b[38;5;241m=\u001b[39m model(batch)  \u001b[38;5;66;03m# (batch, num_masks, num_items)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:317\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    257\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMutableMapping):\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# The mapping type may have extra properties, so we can't just\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# use `type(data)(...)` to create the new mapping.\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# Create a clone and update it if the mapping type is mutable.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     clone \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(elem)\n\u001b[0;32m--> 155\u001b[0m     clone\u001b[38;5;241m.\u001b[39mupdate({key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clone\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:155\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMutableMapping):\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# The mapping type may have extra properties, so we can't just\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# use `type(data)(...)` to create the new mapping.\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# Create a clone and update it if the mapping type is mutable.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     clone \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(elem)\n\u001b[0;32m--> 155\u001b[0m     clone\u001b[38;5;241m.\u001b[39mupdate({key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clone\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 142\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:214\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    212\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    213\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [50] at entry 0 and [45] at entry 1"
     ]
    }
   ],
   "source": [
    "model = SequentialRecommender(num_items, embedding_dim, num_heads, num_layers, dropout).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        seq = batch[\"seq\"].to(device)\n",
    "        logits = model(batch)  # (batch, num_masks, num_items)\n",
    "        mask_positions = batch[\"mask_positions\"].to(device)\n",
    "\n",
    "        loss = 0\n",
    "        for b in range(logits.shape[0]):\n",
    "            targets = seq[b, mask_positions[b]]  # Ground truth items\n",
    "            pred = logits[b]  # (num_masks, num_items)\n",
    "            loss += criterion(pred, targets)\n",
    "        loss /= logits.shape[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d151ba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "evaluate(model, user_dict, num_items, max_seq_length, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cb53f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 6040, Number of items: 3416\n",
      "Length of dataloader: 189\n",
      "Batch 0, Loss: 8.2981\n",
      "Batch 1, Loss: 8.2639\n",
      "Batch 2, Loss: 8.2037\n",
      "Batch 3, Loss: 8.1691\n",
      "Batch 4, Loss: 8.0988\n",
      "Batch 5, Loss: 8.0397\n",
      "Batch 6, Loss: 8.0428\n",
      "Batch 7, Loss: 7.9012\n",
      "Batch 8, Loss: 7.9642\n",
      "Batch 9, Loss: 7.8748\n",
      "Batch 10, Loss: 7.8129\n",
      "Batch 11, Loss: 7.7404\n",
      "Batch 12, Loss: 7.7717\n",
      "Batch 13, Loss: 7.6499\n",
      "Batch 14, Loss: 7.7104\n",
      "Batch 15, Loss: 7.6264\n",
      "Batch 16, Loss: 7.6339\n",
      "Batch 17, Loss: 7.5514\n",
      "Batch 18, Loss: 7.5494\n",
      "Batch 19, Loss: 7.4250\n",
      "Batch 20, Loss: 7.5327\n",
      "Batch 21, Loss: 7.4815\n",
      "Batch 22, Loss: 7.5279\n",
      "Batch 23, Loss: 7.4984\n",
      "Batch 24, Loss: 7.3973\n",
      "Batch 25, Loss: 7.4732\n",
      "Batch 26, Loss: 7.5057\n",
      "Batch 27, Loss: 7.4662\n",
      "Batch 28, Loss: 7.2851\n",
      "Batch 29, Loss: 7.4433\n",
      "Batch 30, Loss: 7.3849\n",
      "Batch 31, Loss: 7.3621\n",
      "Batch 32, Loss: 7.3990\n",
      "Batch 33, Loss: 7.5798\n",
      "Batch 34, Loss: 7.3565\n",
      "Batch 35, Loss: 7.4002\n",
      "Batch 36, Loss: 7.3881\n",
      "Batch 37, Loss: 7.5649\n",
      "Batch 38, Loss: 7.3811\n",
      "Batch 39, Loss: 7.3479\n",
      "Batch 40, Loss: 7.5528\n",
      "Batch 41, Loss: 7.3787\n",
      "Batch 42, Loss: 7.3948\n",
      "Batch 43, Loss: 7.2528\n",
      "Batch 44, Loss: 7.4782\n",
      "Batch 45, Loss: 7.4791\n",
      "Batch 46, Loss: 7.2934\n",
      "Batch 47, Loss: 7.5154\n",
      "Batch 48, Loss: 7.3069\n",
      "Batch 49, Loss: 7.3158\n",
      "Batch 50, Loss: 7.5053\n",
      "Batch 51, Loss: 7.3216\n",
      "Batch 52, Loss: 7.3312\n",
      "Batch 53, Loss: 7.4816\n",
      "Batch 54, Loss: 7.4999\n",
      "Batch 55, Loss: 7.3619\n",
      "Batch 56, Loss: 7.4494\n",
      "Batch 57, Loss: 7.4005\n",
      "Batch 58, Loss: 7.5008\n",
      "Batch 59, Loss: 7.3697\n",
      "Batch 60, Loss: 7.3812\n",
      "Batch 61, Loss: 7.4084\n",
      "Batch 62, Loss: 7.3262\n",
      "Batch 63, Loss: 7.2552\n",
      "Batch 64, Loss: 7.4715\n",
      "Batch 65, Loss: 7.3962\n",
      "Batch 66, Loss: 7.2655\n",
      "Batch 67, Loss: 7.4934\n",
      "Batch 68, Loss: 7.4436\n",
      "Batch 69, Loss: 7.4304\n",
      "Batch 70, Loss: 7.3857\n",
      "Batch 71, Loss: 7.4333\n",
      "Batch 72, Loss: 7.2281\n",
      "Batch 73, Loss: 7.3544\n",
      "Batch 74, Loss: 7.4530\n",
      "Batch 75, Loss: 7.3395\n",
      "Batch 76, Loss: 7.4693\n",
      "Batch 77, Loss: 7.5869\n",
      "Batch 78, Loss: 7.4516\n",
      "Batch 79, Loss: 7.3544\n",
      "Batch 80, Loss: 7.4208\n",
      "Batch 81, Loss: 7.1852\n",
      "Batch 82, Loss: 7.3796\n",
      "Batch 83, Loss: 7.5143\n",
      "Batch 84, Loss: 7.3154\n",
      "Batch 85, Loss: 7.3423\n",
      "Batch 86, Loss: 7.3435\n",
      "Batch 87, Loss: 7.3029\n",
      "Batch 88, Loss: 7.3676\n",
      "Batch 89, Loss: 7.3376\n",
      "Batch 90, Loss: 7.2974\n",
      "Batch 91, Loss: 7.4397\n",
      "Batch 92, Loss: 7.3523\n",
      "Batch 93, Loss: 7.4584\n",
      "Batch 94, Loss: 7.5275\n",
      "Batch 95, Loss: 7.2245\n",
      "Batch 96, Loss: 7.2605\n",
      "Batch 97, Loss: 7.2878\n",
      "Batch 98, Loss: 7.3358\n",
      "Batch 99, Loss: 7.4189\n",
      "Batch 100, Loss: 7.3469\n",
      "Batch 101, Loss: 7.1905\n",
      "Batch 102, Loss: 7.2145\n",
      "Batch 103, Loss: 7.4841\n",
      "Batch 104, Loss: 7.3608\n",
      "Batch 105, Loss: 7.3022\n",
      "Batch 106, Loss: 7.4370\n",
      "Batch 107, Loss: 7.3276\n",
      "Batch 108, Loss: 7.3704\n",
      "Batch 109, Loss: 7.5124\n",
      "Batch 110, Loss: 7.3494\n",
      "Batch 111, Loss: 7.4769\n",
      "Batch 112, Loss: 7.2582\n",
      "Batch 113, Loss: 7.4362\n",
      "Batch 114, Loss: 7.3726\n",
      "Batch 115, Loss: 7.2881\n",
      "Batch 116, Loss: 7.3752\n",
      "Batch 117, Loss: 7.4497\n",
      "Batch 118, Loss: 7.1880\n",
      "Batch 119, Loss: 7.2768\n",
      "Batch 120, Loss: 7.3458\n",
      "Batch 121, Loss: 7.2349\n",
      "Batch 122, Loss: 7.2816\n",
      "Batch 123, Loss: 7.2451\n",
      "Batch 124, Loss: 7.3707\n",
      "Batch 125, Loss: 7.2914\n",
      "Batch 126, Loss: 7.2288\n",
      "Batch 127, Loss: 7.2135\n",
      "Batch 128, Loss: 7.2240\n",
      "Batch 129, Loss: 7.3636\n",
      "Batch 130, Loss: 7.1852\n",
      "Batch 131, Loss: 7.2807\n",
      "Batch 132, Loss: 7.2559\n",
      "Batch 133, Loss: 7.2934\n",
      "Batch 134, Loss: 7.2996\n",
      "Batch 135, Loss: 7.3782\n",
      "Batch 136, Loss: 7.2958\n",
      "Batch 137, Loss: 7.2396\n",
      "Batch 138, Loss: 7.1719\n",
      "Batch 139, Loss: 7.3066\n",
      "Batch 140, Loss: 7.3087\n",
      "Batch 141, Loss: 7.2715\n",
      "Batch 142, Loss: 7.3875\n",
      "Batch 143, Loss: 7.2812\n",
      "Batch 144, Loss: 7.1820\n",
      "Batch 145, Loss: 7.1698\n",
      "Batch 146, Loss: 7.2058\n",
      "Batch 147, Loss: 7.4162\n",
      "Batch 148, Loss: 7.3946\n",
      "Batch 149, Loss: 7.1396\n",
      "Batch 150, Loss: 7.2508\n",
      "Batch 151, Loss: 7.2702\n",
      "Batch 152, Loss: 7.1037\n",
      "Batch 153, Loss: 7.3777\n",
      "Batch 154, Loss: 7.2870\n",
      "Batch 155, Loss: 7.4181\n",
      "Batch 156, Loss: 7.1911\n",
      "Batch 157, Loss: 7.2917\n",
      "Batch 158, Loss: 7.2698\n",
      "Batch 159, Loss: 7.2987\n",
      "Batch 160, Loss: 7.2135\n",
      "Batch 161, Loss: 7.2136\n",
      "Batch 162, Loss: 7.4476\n",
      "Batch 163, Loss: 7.1650\n",
      "Batch 164, Loss: 7.1993\n",
      "Batch 165, Loss: 7.3384\n",
      "Batch 166, Loss: 7.1965\n",
      "Batch 167, Loss: 7.2090\n",
      "Batch 168, Loss: 7.3121\n",
      "Batch 169, Loss: 7.2553\n",
      "Batch 170, Loss: 7.2538\n",
      "Batch 171, Loss: 7.1946\n",
      "Batch 172, Loss: 7.0300\n",
      "Batch 173, Loss: 7.2023\n",
      "Batch 174, Loss: 7.0553\n",
      "Batch 175, Loss: 7.2020\n",
      "Batch 176, Loss: 7.2024\n",
      "Batch 177, Loss: 7.2487\n",
      "Batch 178, Loss: 7.2136\n",
      "Batch 179, Loss: 7.1868\n",
      "Batch 180, Loss: 7.2937\n",
      "Batch 181, Loss: 7.3520\n",
      "Batch 182, Loss: 7.2104\n",
      "Batch 183, Loss: 7.5412\n",
      "Batch 184, Loss: 7.1678\n",
      "Batch 185, Loss: 7.2997\n",
      "Batch 186, Loss: 7.2635\n",
      "Batch 187, Loss: 7.1876\n",
      "Batch 188, Loss: 7.2831\n",
      "Epoch 1, Loss: 7.3932\n",
      "Batch 0, Loss: 7.2664\n",
      "Batch 1, Loss: 7.1434\n",
      "Batch 2, Loss: 7.1316\n",
      "Batch 3, Loss: 7.1600\n",
      "Batch 4, Loss: 7.3542\n",
      "Batch 5, Loss: 7.3278\n",
      "Batch 6, Loss: 7.1168\n",
      "Batch 7, Loss: 7.0804\n",
      "Batch 8, Loss: 7.2552\n",
      "Batch 9, Loss: 7.1539\n",
      "Batch 10, Loss: 7.2275\n",
      "Batch 11, Loss: 7.2025\n",
      "Batch 12, Loss: 7.0863\n",
      "Batch 13, Loss: 7.1887\n",
      "Batch 14, Loss: 7.2524\n",
      "Batch 15, Loss: 7.1029\n",
      "Batch 16, Loss: 7.1671\n",
      "Batch 17, Loss: 7.1197\n",
      "Batch 18, Loss: 7.1725\n",
      "Batch 19, Loss: 7.2599\n",
      "Batch 20, Loss: 7.1944\n",
      "Batch 21, Loss: 7.0532\n",
      "Batch 22, Loss: 7.1253\n",
      "Batch 23, Loss: 7.1663\n",
      "Batch 24, Loss: 7.1632\n",
      "Batch 25, Loss: 7.1142\n",
      "Batch 26, Loss: 7.0265\n",
      "Batch 27, Loss: 7.0369\n",
      "Batch 28, Loss: 7.1561\n",
      "Batch 29, Loss: 7.2125\n",
      "Batch 30, Loss: 6.9935\n",
      "Batch 31, Loss: 7.2846\n",
      "Batch 32, Loss: 7.1797\n",
      "Batch 33, Loss: 7.1083\n",
      "Batch 34, Loss: 7.2293\n",
      "Batch 35, Loss: 7.0661\n",
      "Batch 36, Loss: 7.2395\n",
      "Batch 37, Loss: 6.9091\n",
      "Batch 38, Loss: 7.2322\n",
      "Batch 39, Loss: 7.2007\n",
      "Batch 40, Loss: 6.9987\n",
      "Batch 41, Loss: 7.1779\n",
      "Batch 42, Loss: 7.1406\n",
      "Batch 43, Loss: 7.0382\n",
      "Batch 44, Loss: 7.0349\n",
      "Batch 45, Loss: 7.0425\n",
      "Batch 46, Loss: 7.1476\n",
      "Batch 47, Loss: 7.3292\n",
      "Batch 48, Loss: 7.1847\n",
      "Batch 49, Loss: 7.1586\n",
      "Batch 50, Loss: 7.0302\n",
      "Batch 51, Loss: 6.9969\n",
      "Batch 52, Loss: 6.9970\n",
      "Batch 53, Loss: 7.1238\n",
      "Batch 54, Loss: 7.2665\n",
      "Batch 55, Loss: 7.0349\n",
      "Batch 56, Loss: 7.1143\n",
      "Batch 57, Loss: 7.1513\n",
      "Batch 58, Loss: 7.0221\n",
      "Batch 59, Loss: 7.1991\n",
      "Batch 60, Loss: 7.1216\n",
      "Batch 61, Loss: 7.0656\n",
      "Batch 62, Loss: 7.0813\n",
      "Batch 63, Loss: 6.9193\n",
      "Batch 64, Loss: 7.0733\n",
      "Batch 65, Loss: 6.9221\n",
      "Batch 66, Loss: 7.0285\n",
      "Batch 67, Loss: 7.1433\n",
      "Batch 68, Loss: 7.0139\n",
      "Batch 69, Loss: 7.2121\n",
      "Batch 70, Loss: 7.0105\n",
      "Batch 71, Loss: 6.9169\n",
      "Batch 72, Loss: 7.1075\n",
      "Batch 73, Loss: 7.0000\n",
      "Batch 74, Loss: 7.0889\n",
      "Batch 75, Loss: 7.1230\n",
      "Batch 76, Loss: 6.8177\n",
      "Batch 77, Loss: 7.0071\n",
      "Batch 78, Loss: 6.9304\n",
      "Batch 79, Loss: 7.0729\n",
      "Batch 80, Loss: 6.8956\n",
      "Batch 81, Loss: 7.0230\n",
      "Batch 82, Loss: 7.0100\n",
      "Batch 83, Loss: 7.0786\n",
      "Batch 84, Loss: 6.9545\n",
      "Batch 85, Loss: 6.9432\n",
      "Batch 86, Loss: 7.0926\n",
      "Batch 87, Loss: 7.0997\n",
      "Batch 88, Loss: 6.9269\n",
      "Batch 89, Loss: 7.0284\n",
      "Batch 90, Loss: 6.9129\n",
      "Batch 91, Loss: 6.9765\n",
      "Batch 92, Loss: 6.9579\n",
      "Batch 93, Loss: 6.9943\n",
      "Batch 94, Loss: 7.0622\n",
      "Batch 95, Loss: 6.9690\n",
      "Batch 96, Loss: 7.0315\n",
      "Batch 97, Loss: 6.9435\n",
      "Batch 98, Loss: 6.9279\n",
      "Batch 99, Loss: 6.9457\n",
      "Batch 100, Loss: 6.8297\n",
      "Batch 101, Loss: 7.0374\n",
      "Batch 102, Loss: 7.1352\n",
      "Batch 103, Loss: 7.0683\n",
      "Batch 104, Loss: 6.8649\n",
      "Batch 105, Loss: 7.0243\n",
      "Batch 106, Loss: 7.0558\n",
      "Batch 107, Loss: 6.9359\n",
      "Batch 108, Loss: 7.0063\n",
      "Batch 109, Loss: 7.0742\n",
      "Batch 110, Loss: 6.8222\n",
      "Batch 111, Loss: 6.9911\n",
      "Batch 112, Loss: 6.9052\n",
      "Batch 113, Loss: 6.7842\n",
      "Batch 114, Loss: 6.8933\n",
      "Batch 115, Loss: 6.8192\n",
      "Batch 116, Loss: 6.9842\n",
      "Batch 117, Loss: 6.8721\n",
      "Batch 118, Loss: 6.7761\n",
      "Batch 119, Loss: 6.8838\n",
      "Batch 120, Loss: 6.9767\n",
      "Batch 121, Loss: 6.8473\n",
      "Batch 122, Loss: 6.7606\n",
      "Batch 123, Loss: 6.8617\n",
      "Batch 124, Loss: 6.9564\n",
      "Batch 125, Loss: 6.8079\n",
      "Batch 126, Loss: 6.8471\n",
      "Batch 127, Loss: 6.8921\n",
      "Batch 128, Loss: 6.8167\n",
      "Batch 129, Loss: 6.8930\n",
      "Batch 130, Loss: 6.9348\n",
      "Batch 131, Loss: 6.9323\n",
      "Batch 132, Loss: 6.7630\n",
      "Batch 133, Loss: 6.8612\n",
      "Batch 134, Loss: 6.7925\n",
      "Batch 135, Loss: 6.8030\n",
      "Batch 136, Loss: 6.9937\n",
      "Batch 137, Loss: 6.8655\n",
      "Batch 138, Loss: 6.8499\n",
      "Batch 139, Loss: 6.8227\n",
      "Batch 140, Loss: 6.7825\n",
      "Batch 141, Loss: 6.8029\n",
      "Batch 142, Loss: 6.9368\n",
      "Batch 143, Loss: 6.9337\n",
      "Batch 144, Loss: 6.9870\n",
      "Batch 145, Loss: 6.8088\n",
      "Batch 146, Loss: 6.7690\n",
      "Batch 147, Loss: 6.6972\n",
      "Batch 148, Loss: 6.9179\n",
      "Batch 149, Loss: 6.7700\n",
      "Batch 150, Loss: 6.7152\n",
      "Batch 151, Loss: 6.8026\n",
      "Batch 152, Loss: 6.9140\n",
      "Batch 153, Loss: 6.8367\n",
      "Batch 154, Loss: 6.9057\n",
      "Batch 155, Loss: 6.6979\n",
      "Batch 156, Loss: 6.7860\n",
      "Batch 157, Loss: 6.7259\n",
      "Batch 158, Loss: 7.0027\n",
      "Batch 159, Loss: 6.5707\n",
      "Batch 160, Loss: 6.7573\n",
      "Batch 161, Loss: 6.7734\n",
      "Batch 162, Loss: 6.9324\n",
      "Batch 163, Loss: 6.6747\n",
      "Batch 164, Loss: 6.5870\n",
      "Batch 165, Loss: 6.9214\n",
      "Batch 166, Loss: 6.8564\n",
      "Batch 167, Loss: 6.8756\n",
      "Batch 168, Loss: 6.7863\n",
      "Batch 169, Loss: 6.7691\n",
      "Batch 170, Loss: 6.8821\n",
      "Batch 171, Loss: 6.7225\n",
      "Batch 172, Loss: 6.7442\n",
      "Batch 173, Loss: 6.9235\n",
      "Batch 174, Loss: 6.7408\n",
      "Batch 175, Loss: 6.7139\n",
      "Batch 176, Loss: 6.7671\n",
      "Batch 177, Loss: 6.6139\n",
      "Batch 178, Loss: 6.7918\n",
      "Batch 179, Loss: 6.6972\n",
      "Batch 180, Loss: 6.6399\n",
      "Batch 181, Loss: 6.7553\n",
      "Batch 182, Loss: 6.5769\n",
      "Batch 183, Loss: 6.7680\n",
      "Batch 184, Loss: 6.6877\n",
      "Batch 185, Loss: 6.6636\n",
      "Batch 186, Loss: 6.6390\n",
      "Batch 187, Loss: 6.7480\n",
      "Batch 188, Loss: 6.7781\n",
      "Epoch 2, Loss: 6.9697\n",
      "Batch 0, Loss: 6.5846\n",
      "Batch 1, Loss: 6.8490\n",
      "Batch 2, Loss: 6.8002\n",
      "Batch 3, Loss: 6.6718\n",
      "Batch 4, Loss: 6.8089\n",
      "Batch 5, Loss: 6.6692\n",
      "Batch 6, Loss: 6.7541\n",
      "Batch 7, Loss: 6.6099\n",
      "Batch 8, Loss: 6.6763\n",
      "Batch 9, Loss: 6.6815\n",
      "Batch 10, Loss: 6.6708\n",
      "Batch 11, Loss: 6.5233\n",
      "Batch 12, Loss: 6.3233\n",
      "Batch 13, Loss: 6.5750\n",
      "Batch 14, Loss: 6.6854\n",
      "Batch 15, Loss: 6.6784\n",
      "Batch 16, Loss: 6.7329\n",
      "Batch 17, Loss: 6.7707\n",
      "Batch 18, Loss: 6.7721\n",
      "Batch 19, Loss: 6.5923\n",
      "Batch 20, Loss: 6.7719\n",
      "Batch 21, Loss: 6.8043\n",
      "Batch 22, Loss: 6.5671\n",
      "Batch 23, Loss: 6.5124\n",
      "Batch 24, Loss: 6.5808\n",
      "Batch 25, Loss: 6.6392\n",
      "Batch 26, Loss: 6.4806\n",
      "Batch 27, Loss: 6.5774\n",
      "Batch 28, Loss: 6.5664\n",
      "Batch 29, Loss: 6.5819\n",
      "Batch 30, Loss: 6.5701\n",
      "Batch 31, Loss: 6.6804\n",
      "Batch 32, Loss: 6.5291\n",
      "Batch 33, Loss: 6.5497\n",
      "Batch 34, Loss: 6.7518\n",
      "Batch 35, Loss: 6.5663\n",
      "Batch 36, Loss: 6.7905\n",
      "Batch 37, Loss: 6.6808\n",
      "Batch 38, Loss: 6.6163\n",
      "Batch 39, Loss: 6.6380\n",
      "Batch 40, Loss: 6.6570\n",
      "Batch 41, Loss: 6.5757\n",
      "Batch 42, Loss: 6.6207\n",
      "Batch 43, Loss: 6.4835\n",
      "Batch 44, Loss: 6.7001\n",
      "Batch 45, Loss: 6.5219\n",
      "Batch 46, Loss: 6.7548\n",
      "Batch 47, Loss: 6.5417\n",
      "Batch 48, Loss: 6.3811\n",
      "Batch 49, Loss: 6.5613\n",
      "Batch 50, Loss: 6.3856\n",
      "Batch 51, Loss: 6.5108\n",
      "Batch 52, Loss: 6.4536\n",
      "Batch 53, Loss: 6.4398\n",
      "Batch 54, Loss: 6.5750\n",
      "Batch 55, Loss: 6.4617\n",
      "Batch 56, Loss: 6.3596\n",
      "Batch 57, Loss: 6.3972\n",
      "Batch 58, Loss: 6.5775\n",
      "Batch 59, Loss: 6.3803\n",
      "Batch 60, Loss: 6.5986\n",
      "Batch 61, Loss: 6.8057\n",
      "Batch 62, Loss: 6.6910\n",
      "Batch 63, Loss: 6.6595\n",
      "Batch 64, Loss: 6.7062\n",
      "Batch 65, Loss: 6.5941\n",
      "Batch 66, Loss: 6.5784\n",
      "Batch 67, Loss: 6.6684\n",
      "Batch 68, Loss: 6.3735\n",
      "Batch 69, Loss: 6.3702\n",
      "Batch 70, Loss: 6.5762\n",
      "Batch 71, Loss: 6.5329\n",
      "Batch 72, Loss: 6.5144\n",
      "Batch 73, Loss: 6.4983\n",
      "Batch 74, Loss: 6.3683\n",
      "Batch 75, Loss: 6.4260\n",
      "Batch 76, Loss: 6.5703\n",
      "Batch 77, Loss: 6.6407\n",
      "Batch 78, Loss: 6.5390\n",
      "Batch 79, Loss: 6.2497\n",
      "Batch 80, Loss: 6.5547\n",
      "Batch 81, Loss: 6.5353\n",
      "Batch 82, Loss: 6.3678\n",
      "Batch 83, Loss: 6.7108\n",
      "Batch 84, Loss: 6.4266\n",
      "Batch 85, Loss: 6.6030\n",
      "Batch 86, Loss: 6.3888\n",
      "Batch 87, Loss: 6.5354\n",
      "Batch 88, Loss: 6.4095\n",
      "Batch 89, Loss: 6.2325\n",
      "Batch 90, Loss: 6.3338\n",
      "Batch 91, Loss: 6.4103\n",
      "Batch 92, Loss: 6.4177\n",
      "Batch 93, Loss: 6.5915\n",
      "Batch 94, Loss: 6.3059\n",
      "Batch 95, Loss: 6.3649\n",
      "Batch 96, Loss: 6.3614\n",
      "Batch 97, Loss: 6.5979\n",
      "Batch 98, Loss: 6.2588\n",
      "Batch 99, Loss: 6.6426\n",
      "Batch 100, Loss: 6.4561\n",
      "Batch 101, Loss: 6.4845\n",
      "Batch 102, Loss: 6.4677\n",
      "Batch 103, Loss: 6.4579\n",
      "Batch 104, Loss: 6.4889\n",
      "Batch 105, Loss: 6.5103\n",
      "Batch 106, Loss: 6.5731\n",
      "Batch 107, Loss: 6.4144\n",
      "Batch 108, Loss: 6.4496\n",
      "Batch 109, Loss: 6.4001\n",
      "Batch 110, Loss: 6.5836\n",
      "Batch 111, Loss: 6.3185\n",
      "Batch 112, Loss: 6.3844\n",
      "Batch 113, Loss: 6.6654\n",
      "Batch 114, Loss: 6.3701\n",
      "Batch 115, Loss: 6.3606\n",
      "Batch 116, Loss: 6.2104\n",
      "Batch 117, Loss: 6.5764\n",
      "Batch 118, Loss: 6.4691\n",
      "Batch 119, Loss: 6.3042\n",
      "Batch 120, Loss: 6.5579\n",
      "Batch 121, Loss: 6.3674\n",
      "Batch 122, Loss: 6.4316\n",
      "Batch 123, Loss: 6.2850\n",
      "Batch 124, Loss: 6.5203\n",
      "Batch 125, Loss: 6.3651\n",
      "Batch 126, Loss: 6.0994\n",
      "Batch 127, Loss: 6.3868\n",
      "Batch 128, Loss: 6.5785\n",
      "Batch 129, Loss: 6.2121\n",
      "Batch 130, Loss: 6.5095\n",
      "Batch 131, Loss: 6.3065\n",
      "Batch 132, Loss: 6.4956\n",
      "Batch 133, Loss: 6.4938\n",
      "Batch 134, Loss: 6.3817\n",
      "Batch 135, Loss: 6.1467\n",
      "Batch 136, Loss: 6.4263\n",
      "Batch 137, Loss: 6.1565\n",
      "Batch 138, Loss: 6.3632\n",
      "Batch 139, Loss: 6.2531\n",
      "Batch 140, Loss: 6.3496\n",
      "Batch 141, Loss: 6.2670\n",
      "Batch 142, Loss: 6.4591\n",
      "Batch 143, Loss: 6.2335\n",
      "Batch 144, Loss: 6.2623\n",
      "Batch 145, Loss: 6.4724\n",
      "Batch 146, Loss: 6.6795\n",
      "Batch 147, Loss: 6.4077\n",
      "Batch 148, Loss: 6.3626\n",
      "Batch 149, Loss: 6.4582\n",
      "Batch 150, Loss: 6.2971\n",
      "Batch 151, Loss: 6.2995\n",
      "Batch 152, Loss: 6.2926\n",
      "Batch 153, Loss: 6.4478\n",
      "Batch 154, Loss: 6.3497\n",
      "Batch 155, Loss: 6.4426\n",
      "Batch 156, Loss: 6.4063\n",
      "Batch 157, Loss: 6.3557\n",
      "Batch 158, Loss: 6.3091\n",
      "Batch 159, Loss: 6.3325\n",
      "Batch 160, Loss: 6.4871\n",
      "Batch 161, Loss: 6.2586\n",
      "Batch 162, Loss: 6.2590\n",
      "Batch 163, Loss: 6.2590\n",
      "Batch 164, Loss: 6.3070\n",
      "Batch 165, Loss: 6.2377\n",
      "Batch 166, Loss: 6.3163\n",
      "Batch 167, Loss: 6.3286\n",
      "Batch 168, Loss: 6.3984\n",
      "Batch 169, Loss: 6.3388\n",
      "Batch 170, Loss: 6.3964\n",
      "Batch 171, Loss: 6.2468\n",
      "Batch 172, Loss: 6.3557\n",
      "Batch 173, Loss: 6.2959\n",
      "Batch 174, Loss: 6.2736\n",
      "Batch 175, Loss: 6.2674\n",
      "Batch 176, Loss: 6.4546\n",
      "Batch 177, Loss: 6.3448\n",
      "Batch 178, Loss: 6.5330\n",
      "Batch 179, Loss: 6.3528\n",
      "Batch 180, Loss: 6.2732\n",
      "Batch 181, Loss: 6.2074\n",
      "Batch 182, Loss: 6.1103\n",
      "Batch 183, Loss: 6.3748\n",
      "Batch 184, Loss: 6.3490\n",
      "Batch 185, Loss: 6.5043\n",
      "Batch 186, Loss: 6.4081\n",
      "Batch 187, Loss: 6.4678\n",
      "Batch 188, Loss: 6.2272\n",
      "Epoch 3, Loss: 6.4743\n",
      "Batch 0, Loss: 6.2443\n",
      "Batch 1, Loss: 6.3526\n",
      "Batch 2, Loss: 6.4254\n",
      "Batch 3, Loss: 6.1205\n",
      "Batch 4, Loss: 6.4400\n",
      "Batch 5, Loss: 6.2719\n",
      "Batch 6, Loss: 6.2176\n",
      "Batch 7, Loss: 6.2288\n",
      "Batch 8: Logits shape torch.Size([534, 3416]), Targets shape torch.Size([533])\n",
      "Batch 9, Loss: 6.2348\n",
      "Batch 10, Loss: 6.3294\n",
      "Batch 11, Loss: 6.3994\n",
      "Batch 12, Loss: 6.3105\n",
      "Batch 13, Loss: 6.0386\n",
      "Batch 14, Loss: 6.3551\n",
      "Batch 15, Loss: 6.1805\n",
      "Batch 16, Loss: 6.1435\n",
      "Batch 17, Loss: 6.2787\n",
      "Batch 18, Loss: 6.2584\n",
      "Batch 19, Loss: 6.1937\n",
      "Batch 20, Loss: 6.2592\n",
      "Batch 21, Loss: 6.2355\n",
      "Batch 22, Loss: 6.1708\n",
      "Batch 23, Loss: 6.3300\n",
      "Batch 24, Loss: 6.2106\n",
      "Batch 25, Loss: 6.1502\n",
      "Batch 26, Loss: 6.2185\n",
      "Batch 27, Loss: 6.2673\n",
      "Batch 28, Loss: 6.1380\n",
      "Batch 29, Loss: 6.1562\n",
      "Batch 30, Loss: 6.0162\n",
      "Batch 31, Loss: 6.0457\n",
      "Batch 32, Loss: 6.0285\n",
      "Batch 33, Loss: 6.2978\n",
      "Batch 34, Loss: 6.1499\n",
      "Batch 35, Loss: 6.4519\n",
      "Batch 36, Loss: 6.3112\n",
      "Batch 37, Loss: 6.0587\n",
      "Batch 38, Loss: 6.1706\n",
      "Batch 39, Loss: 6.1860\n",
      "Batch 40, Loss: 6.1435\n",
      "Batch 41, Loss: 6.0811\n",
      "Batch 42, Loss: 6.2842\n",
      "Batch 43, Loss: 6.2038\n",
      "Batch 44, Loss: 6.1231\n",
      "Batch 45, Loss: 6.1924\n",
      "Batch 46, Loss: 6.0778\n",
      "Batch 47, Loss: 6.1209\n",
      "Batch 48, Loss: 6.2460\n",
      "Batch 49, Loss: 6.2202\n",
      "Batch 50, Loss: 6.1477\n",
      "Batch 51, Loss: 6.0561\n",
      "Batch 52, Loss: 6.3469\n",
      "Batch 53, Loss: 6.1423\n",
      "Batch 54, Loss: 6.2915\n",
      "Batch 55, Loss: 6.0875\n",
      "Batch 56, Loss: 6.1635\n",
      "Batch 57, Loss: 5.9896\n",
      "Batch 58, Loss: 6.2320\n",
      "Batch 59, Loss: 6.3214\n",
      "Batch 60, Loss: 6.3910\n",
      "Batch 61, Loss: 6.1302\n",
      "Batch 62, Loss: 6.0816\n",
      "Batch 63, Loss: 6.0295\n",
      "Batch 64, Loss: 6.2124\n",
      "Batch 65, Loss: 6.1409\n",
      "Batch 66, Loss: 6.3898\n",
      "Batch 67, Loss: 6.1529\n",
      "Batch 68, Loss: 6.2584\n",
      "Batch 69, Loss: 5.8138\n",
      "Batch 70, Loss: 5.9510\n",
      "Batch 71, Loss: 6.2987\n",
      "Batch 72, Loss: 6.1331\n",
      "Batch 73, Loss: 6.2955\n",
      "Batch 74, Loss: 5.9997\n",
      "Batch 75, Loss: 6.2456\n",
      "Batch 76, Loss: 6.0795\n",
      "Batch 77, Loss: 6.1849\n",
      "Batch 78, Loss: 6.2364\n",
      "Batch 79, Loss: 5.9181\n",
      "Batch 80, Loss: 6.2110\n",
      "Batch 81, Loss: 6.1272\n",
      "Batch 82, Loss: 6.0962\n",
      "Batch 83, Loss: 6.1638\n",
      "Batch 84, Loss: 6.0031\n",
      "Batch 85, Loss: 6.1299\n",
      "Batch 86, Loss: 6.1544\n",
      "Batch 87, Loss: 6.2548\n",
      "Batch 88, Loss: 6.2568\n",
      "Batch 89, Loss: 6.1831\n",
      "Batch 90, Loss: 6.1554\n",
      "Batch 91, Loss: 5.9635\n",
      "Batch 92, Loss: 6.1088\n",
      "Batch 93, Loss: 6.1656\n",
      "Batch 94, Loss: 6.2150\n",
      "Batch 95, Loss: 6.1575\n",
      "Batch 96, Loss: 6.3241\n",
      "Batch 97, Loss: 6.2274\n",
      "Batch 98, Loss: 5.9787\n",
      "Batch 99, Loss: 6.2272\n",
      "Batch 100, Loss: 6.2223\n",
      "Batch 101, Loss: 6.0953\n",
      "Batch 102, Loss: 6.2993\n",
      "Batch 103, Loss: 6.3189\n",
      "Batch 104, Loss: 6.0105\n",
      "Batch 105, Loss: 5.7658\n",
      "Batch 106, Loss: 6.0118\n",
      "Batch 107, Loss: 6.2178\n",
      "Batch 108, Loss: 5.8018\n",
      "Batch 109, Loss: 6.0829\n",
      "Batch 110, Loss: 6.0545\n",
      "Batch 111, Loss: 6.2758\n",
      "Batch 112, Loss: 6.1114\n",
      "Batch 113, Loss: 6.0495\n",
      "Batch 114, Loss: 6.1052\n",
      "Batch 115, Loss: 6.2618\n",
      "Batch 116, Loss: 5.9057\n",
      "Batch 117, Loss: 6.1584\n",
      "Batch 118, Loss: 6.1873\n",
      "Batch 119, Loss: 6.0223\n",
      "Batch 120, Loss: 5.9451\n",
      "Batch 121, Loss: 6.0127\n",
      "Batch 122, Loss: 5.9226\n",
      "Batch 123, Loss: 6.2459\n",
      "Batch 124, Loss: 6.0915\n",
      "Batch 125, Loss: 6.0795\n",
      "Batch 126, Loss: 5.9630\n",
      "Batch 127, Loss: 6.1070\n",
      "Batch 128, Loss: 6.1487\n",
      "Batch 129, Loss: 6.2046\n",
      "Batch 130, Loss: 6.1142\n",
      "Batch 131, Loss: 6.2555\n",
      "Batch 132, Loss: 6.2373\n",
      "Batch 133, Loss: 6.0346\n",
      "Batch 134, Loss: 6.1443\n",
      "Batch 135, Loss: 6.0559\n",
      "Batch 136, Loss: 6.2206\n",
      "Batch 137, Loss: 5.9142\n",
      "Batch 138, Loss: 6.0953\n",
      "Batch 139, Loss: 6.1269\n",
      "Batch 140, Loss: 6.0769\n",
      "Batch 141, Loss: 6.3954\n",
      "Batch 142, Loss: 6.0528\n",
      "Batch 143, Loss: 6.1304\n",
      "Batch 144, Loss: 5.9125\n",
      "Batch 145, Loss: 6.0681\n",
      "Batch 146, Loss: 6.1442\n",
      "Batch 147, Loss: 6.0187\n",
      "Batch 148, Loss: 5.8665\n",
      "Batch 149, Loss: 5.9666\n",
      "Batch 150, Loss: 5.9174\n",
      "Batch 151, Loss: 5.9234\n",
      "Batch 152, Loss: 6.0382\n",
      "Batch 153, Loss: 5.9735\n",
      "Batch 154, Loss: 5.9635\n",
      "Batch 155, Loss: 6.1113\n",
      "Batch 156, Loss: 6.2068\n",
      "Batch 157, Loss: 6.1793\n",
      "Batch 158, Loss: 6.2867\n",
      "Batch 159, Loss: 6.0632\n",
      "Batch 160, Loss: 6.1455\n",
      "Batch 161, Loss: 5.9979\n",
      "Batch 162, Loss: 6.0825\n",
      "Batch 163, Loss: 5.9036\n",
      "Batch 164, Loss: 6.0706\n",
      "Batch 165, Loss: 5.9742\n",
      "Batch 166, Loss: 6.2405\n",
      "Batch 167, Loss: 5.8500\n",
      "Batch 168, Loss: 6.4138\n",
      "Batch 169, Loss: 6.0700\n",
      "Batch 170, Loss: 5.9141\n",
      "Batch 171, Loss: 6.0632\n",
      "Batch 172, Loss: 6.0516\n",
      "Batch 173, Loss: 6.0125\n",
      "Batch 174, Loss: 6.1046\n",
      "Batch 175, Loss: 6.0437\n",
      "Batch 176, Loss: 6.1180\n",
      "Batch 177, Loss: 6.0271\n",
      "Batch 178, Loss: 6.1528\n",
      "Batch 179, Loss: 5.9640\n",
      "Batch 180, Loss: 6.0634\n",
      "Batch 181, Loss: 6.1966\n",
      "Batch 182, Loss: 5.9724\n",
      "Batch 183, Loss: 6.1642\n",
      "Batch 184, Loss: 6.1333\n",
      "Batch 185, Loss: 5.9728\n",
      "Batch 186, Loss: 5.8962\n",
      "Batch 187, Loss: 5.9891\n",
      "Batch 188, Loss: 6.0227\n",
      "Epoch 4, Loss: 6.1015\n",
      "Batch 0, Loss: 6.1689\n",
      "Batch 1, Loss: 6.0119\n",
      "Batch 2, Loss: 6.0498\n",
      "Batch 3, Loss: 5.8295\n",
      "Batch 4, Loss: 6.1289\n",
      "Batch 5, Loss: 5.7999\n",
      "Batch 6, Loss: 6.2417\n",
      "Batch 7, Loss: 5.7197\n",
      "Batch 8, Loss: 5.6838\n",
      "Batch 9, Loss: 6.0267\n",
      "Batch 10, Loss: 6.0081\n",
      "Batch 11, Loss: 5.8617\n",
      "Batch 12, Loss: 6.0164\n",
      "Batch 13, Loss: 5.9264\n",
      "Batch 14, Loss: 5.9340\n",
      "Batch 15, Loss: 5.9581\n",
      "Batch 16, Loss: 6.0692\n",
      "Batch 17, Loss: 6.0293\n",
      "Batch 18, Loss: 5.6802\n",
      "Batch 19, Loss: 5.8075\n",
      "Batch 20, Loss: 5.6812\n",
      "Batch 21, Loss: 5.8021\n",
      "Batch 22, Loss: 6.3442\n",
      "Batch 23, Loss: 5.8232\n",
      "Batch 24, Loss: 5.8322\n",
      "Batch 25, Loss: 6.0092\n",
      "Batch 26, Loss: 5.9098\n",
      "Batch 27, Loss: 5.9078\n",
      "Batch 28, Loss: 6.1573\n",
      "Batch 29, Loss: 6.0526\n",
      "Batch 30, Loss: 6.1125\n",
      "Batch 31, Loss: 5.8679\n",
      "Batch 32: Logits shape torch.Size([529, 3416]), Targets shape torch.Size([528])\n",
      "Batch 33, Loss: 6.0278\n",
      "Batch 34, Loss: 5.9734\n",
      "Batch 35, Loss: 6.0233\n",
      "Batch 36, Loss: 5.9764\n",
      "Batch 37, Loss: 6.1302\n",
      "Batch 38, Loss: 6.2558\n",
      "Batch 39, Loss: 6.0053\n",
      "Batch 40, Loss: 5.8359\n",
      "Batch 41, Loss: 6.0268\n",
      "Batch 42, Loss: 6.0043\n",
      "Batch 43, Loss: 5.8585\n",
      "Batch 44, Loss: 5.7516\n",
      "Batch 45, Loss: 6.0595\n",
      "Batch 46, Loss: 5.9031\n",
      "Batch 47, Loss: 5.9760\n",
      "Batch 48, Loss: 5.8940\n",
      "Batch 49, Loss: 5.7195\n",
      "Batch 50, Loss: 6.0401\n",
      "Batch 51, Loss: 6.2178\n",
      "Batch 52, Loss: 6.1918\n",
      "Batch 53, Loss: 6.0027\n",
      "Batch 54, Loss: 5.7741\n",
      "Batch 55, Loss: 5.8317\n",
      "Batch 56, Loss: 5.7590\n",
      "Batch 57, Loss: 5.8820\n",
      "Batch 58, Loss: 6.2318\n",
      "Batch 59, Loss: 6.0570\n",
      "Batch 60, Loss: 6.0973\n",
      "Batch 61, Loss: 5.9513\n",
      "Batch 62, Loss: 6.0316\n",
      "Batch 63, Loss: 6.2110\n",
      "Batch 64, Loss: 5.8018\n",
      "Batch 65, Loss: 6.0413\n",
      "Batch 66, Loss: 6.0027\n",
      "Batch 67, Loss: 5.8791\n",
      "Batch 68, Loss: 5.8032\n",
      "Batch 69, Loss: 5.9131\n",
      "Batch 70, Loss: 5.8369\n",
      "Batch 71, Loss: 5.9800\n",
      "Batch 72, Loss: 6.2508\n",
      "Batch 73, Loss: 6.1457\n",
      "Batch 74, Loss: 6.0646\n",
      "Batch 75, Loss: 5.9539\n",
      "Batch 76, Loss: 5.8117\n",
      "Batch 77, Loss: 6.0625\n",
      "Batch 78, Loss: 5.8616\n",
      "Batch 79, Loss: 6.0266\n",
      "Batch 80, Loss: 5.9424\n",
      "Batch 81, Loss: 5.8289\n",
      "Batch 82, Loss: 6.0804\n",
      "Batch 83, Loss: 5.9213\n",
      "Batch 84, Loss: 6.0471\n",
      "Batch 85, Loss: 5.9432\n",
      "Batch 86, Loss: 5.8166\n",
      "Batch 87, Loss: 5.9300\n",
      "Batch 88, Loss: 6.0479\n",
      "Batch 89, Loss: 6.3069\n",
      "Batch 90, Loss: 5.7287\n",
      "Batch 91, Loss: 5.9543\n",
      "Batch 92, Loss: 6.1338\n",
      "Batch 93, Loss: 5.8691\n",
      "Batch 94, Loss: 5.8807\n",
      "Batch 95, Loss: 5.8348\n",
      "Batch 96, Loss: 6.0576\n",
      "Batch 97, Loss: 5.8410\n",
      "Batch 98, Loss: 5.9984\n",
      "Batch 99, Loss: 5.9637\n",
      "Batch 100, Loss: 5.7468\n",
      "Batch 101, Loss: 5.8421\n",
      "Batch 102, Loss: 5.9150\n",
      "Batch 103, Loss: 5.8988\n",
      "Batch 104, Loss: 5.8506\n",
      "Batch 105, Loss: 5.8749\n",
      "Batch 106, Loss: 5.8752\n",
      "Batch 107, Loss: 6.1328\n",
      "Batch 108, Loss: 5.7466\n",
      "Batch 109, Loss: 5.9072\n",
      "Batch 110, Loss: 5.7721\n",
      "Batch 111, Loss: 6.0556\n",
      "Batch 112, Loss: 5.9364\n",
      "Batch 113, Loss: 5.9357\n",
      "Batch 114, Loss: 5.8927\n",
      "Batch 115, Loss: 5.8455\n",
      "Batch 116, Loss: 5.8253\n",
      "Batch 117, Loss: 5.9868\n",
      "Batch 118, Loss: 5.9481\n",
      "Batch 119, Loss: 6.1587\n",
      "Batch 120, Loss: 5.6811\n",
      "Batch 121, Loss: 5.9800\n",
      "Batch 122, Loss: 5.7804\n",
      "Batch 123, Loss: 5.7552\n",
      "Batch 124, Loss: 5.7937\n",
      "Batch 125, Loss: 5.8329\n",
      "Batch 126, Loss: 5.7487\n",
      "Batch 127, Loss: 6.1201\n",
      "Batch 128, Loss: 5.8110\n",
      "Batch 129, Loss: 5.6247\n",
      "Batch 130, Loss: 5.7862\n",
      "Batch 131, Loss: 5.9284\n",
      "Batch 132, Loss: 5.9134\n",
      "Batch 133, Loss: 6.0921\n",
      "Batch 134, Loss: 5.5569\n",
      "Batch 135, Loss: 5.8605\n",
      "Batch 136, Loss: 5.7149\n",
      "Batch 137, Loss: 5.9629\n",
      "Batch 138, Loss: 5.9928\n",
      "Batch 139, Loss: 5.7641\n",
      "Batch 140, Loss: 5.8060\n",
      "Batch 141, Loss: 6.0039\n",
      "Batch 142, Loss: 5.9644\n",
      "Batch 143, Loss: 5.9001\n",
      "Batch 144, Loss: 5.6465\n",
      "Batch 145, Loss: 5.7610\n",
      "Batch 146, Loss: 6.0578\n",
      "Batch 147, Loss: 5.9475\n",
      "Batch 148, Loss: 5.5016\n",
      "Batch 149, Loss: 6.0406\n",
      "Batch 150, Loss: 6.1339\n",
      "Batch 151, Loss: 5.5156\n",
      "Batch 152, Loss: 5.7796\n",
      "Batch 153, Loss: 5.8182\n",
      "Batch 154, Loss: 5.8656\n",
      "Batch 155, Loss: 5.6339\n",
      "Batch 156, Loss: 5.8895\n",
      "Batch 157, Loss: 5.7019\n",
      "Batch 158, Loss: 5.7810\n",
      "Batch 159, Loss: 5.8794\n",
      "Batch 160, Loss: 5.9730\n",
      "Batch 161, Loss: 5.5154\n",
      "Batch 162, Loss: 5.8159\n",
      "Batch 163, Loss: 5.8151\n",
      "Batch 164, Loss: 5.7563\n",
      "Batch 165, Loss: 5.9784\n",
      "Batch 166, Loss: 5.9427\n",
      "Batch 167, Loss: 5.7092\n",
      "Batch 168, Loss: 5.8150\n",
      "Batch 169, Loss: 5.7793\n",
      "Batch 170, Loss: 5.7030\n",
      "Batch 171, Loss: 5.7773\n",
      "Batch 172, Loss: 5.9189\n",
      "Batch 173, Loss: 5.5593\n",
      "Batch 174, Loss: 5.9443\n",
      "Batch 175, Loss: 5.7365\n",
      "Batch 176, Loss: 5.8381\n",
      "Batch 177, Loss: 5.7973\n",
      "Batch 178, Loss: 5.9704\n",
      "Batch 179, Loss: 6.1742\n",
      "Batch 180, Loss: 5.6444\n",
      "Batch 181, Loss: 5.7603\n",
      "Batch 182, Loss: 5.7438\n",
      "Batch 183, Loss: 5.9278\n",
      "Batch 184, Loss: 5.8497\n",
      "Batch 185, Loss: 5.9722\n",
      "Batch 186, Loss: 5.7874\n",
      "Batch 187, Loss: 5.7951\n",
      "Batch 188, Loss: 5.7674\n",
      "Epoch 5, Loss: 5.8781\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'window_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 343\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 343\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 260\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, user_dict, num_items, max_seq_length, device)\u001b[0m\n\u001b[1;32m    257\u001b[0m candidates \u001b[38;5;241m=\u001b[39m [target] \u001b[38;5;241m+\u001b[39m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_items \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(items)), num_negatives)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 260\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m     scores \u001b[38;5;241m=\u001b[39m logits[\u001b[38;5;241m0\u001b[39m, candidates]\n\u001b[1;32m    262\u001b[0m     ranked \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margsort(scores, descending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[0;32mIn[3], line 216\u001b[0m, in \u001b[0;36mSequentialRecommender.predict\u001b[0;34m(self, input_seq)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(seq\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m    215\u001b[0m     s \u001b[38;5;241m=\u001b[39m seq[b]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m--> 216\u001b[0m     compressed, chunk_map \u001b[38;5;241m=\u001b[39m \u001b[43mMovieLensDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnext_pos\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m     compressed_seqs\u001b[38;5;241m.\u001b[39mappend(compressed)\n\u001b[1;32m    218\u001b[0m     chunk_maps\u001b[38;5;241m.\u001b[39mappend(chunk_map)\n",
      "Cell \u001b[0;32mIn[3], line 98\u001b[0m, in \u001b[0;36mMovieLensDataset.compress_sequence\u001b[0;34m(self, seq, mask_positions)\u001b[0m\n\u001b[1;32m     96\u001b[0m windows \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(mask_positions):\n\u001b[0;32m---> 98\u001b[0m     start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, pos \u001b[38;5;241m-\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwindow_size\u001b[49m)\n\u001b[1;32m     99\u001b[0m     end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(seq), pos \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    100\u001b[0m     windows\u001b[38;5;241m.\u001b[39mappend((start, end))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'window_size'"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 128\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "dropout = 0.1\n",
    "max_seq_length = 200\n",
    "window_size = 50\n",
    "chunk_size = 100\n",
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "mask_prob = 0.15\n",
    "num_negatives = 99\n",
    "\n",
    "# Custom collation function\n",
    "def custom_collate_fn(batch):\n",
    "    seqs = [item[\"seq\"] for item in batch]\n",
    "    compressed_seqs = [item[\"compressed_seq\"] for item in batch]\n",
    "    mask_positions = [item[\"mask_positions\"] for item in batch]\n",
    "    chunk_maps = [item[\"chunk_map\"] for item in batch]\n",
    "\n",
    "    max_comp_len = max(len(cs) for cs in compressed_seqs)\n",
    "    max_mask_len = max(len(mp) for mp in mask_positions)\n",
    "\n",
    "    seqs_padded = torch.stack(seqs)\n",
    "    compressed_seqs_padded = torch.zeros(len(batch), max_comp_len, dtype=torch.long)\n",
    "    mask_positions_padded = torch.zeros(len(batch), max_mask_len, dtype=torch.long)\n",
    "\n",
    "    for i in range(len(batch)):\n",
    "        compressed_seqs_padded[i, :len(compressed_seqs[i])] = compressed_seqs[i]\n",
    "        mask_positions_padded[i, :len(mask_positions[i])] = mask_positions[i]\n",
    "\n",
    "    return {\n",
    "        \"seq\": seqs_padded,\n",
    "        \"compressed_seq\": compressed_seqs_padded,\n",
    "        \"mask_positions\": mask_positions_padded,\n",
    "        \"chunk_map\": chunk_maps\n",
    "    }\n",
    "\n",
    "# Dataset class\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, user_dict, num_items, max_seq_length, window_size, mask_prob):\n",
    "        self.user_dict = user_dict\n",
    "        self.num_items = num_items\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.window_size = window_size\n",
    "        self.mask_prob = mask_prob\n",
    "        self.users = list(user_dict.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user = self.users[idx]\n",
    "        seq = self.user_dict[user][:self.max_seq_length]\n",
    "        if len(seq) < 2:\n",
    "            seq = [0] * self.max_seq_length\n",
    "        return self.process_sequence(seq)\n",
    "\n",
    "    def process_sequence(self, seq):\n",
    "        seq = seq[:self.max_seq_length]\n",
    "        if len(seq) < self.max_seq_length:\n",
    "            seq = seq + [0] * (self.max_seq_length - len(seq))\n",
    "\n",
    "        mask_positions = []\n",
    "        masked_seq = seq.copy()\n",
    "        for i in range(len(seq)):\n",
    "            if seq[i] == 0:\n",
    "                continue\n",
    "            if random.random() < self.mask_prob:\n",
    "                mask_positions.append(i)\n",
    "                if random.random() < 0.8:\n",
    "                    masked_seq[i] = self.num_items  # Use num_items as [MASK]\n",
    "                elif random.random() < 0.5:\n",
    "                    masked_seq[i] = random.randint(1, self.num_items)\n",
    "                # Else keep original\n",
    "\n",
    "        if not mask_positions:\n",
    "            i = random.randint(0, len(seq) - 1)\n",
    "            while seq[i] == 0:\n",
    "                i = random.randint(0, len(seq) - 1)\n",
    "            mask_positions.append(i)\n",
    "            masked_seq[i] = self.num_items\n",
    "\n",
    "        compressed_seq, chunk_map = self.compress_sequence(masked_seq, mask_positions)\n",
    "        return {\n",
    "            \"seq\": torch.tensor(seq, dtype=torch.long),\n",
    "            \"compressed_seq\": torch.tensor(compressed_seq, dtype=torch.long),\n",
    "            \"mask_positions\": torch.tensor(mask_positions, dtype=torch.long),\n",
    "            \"chunk_map\": chunk_map\n",
    "        }\n",
    "\n",
    "    def compress_sequence(self, seq, mask_positions):\n",
    "        windows = []\n",
    "        for pos in sorted(mask_positions):\n",
    "            start = max(0, pos - self.window_size)\n",
    "            end = min(len(seq), pos + self.window_size + 1)\n",
    "            windows.append((start, end))\n",
    "\n",
    "        merged = []\n",
    "        if windows:\n",
    "            current_start, current_end = windows[0]\n",
    "            for start, end in windows[1:]:\n",
    "                if start <= current_end:\n",
    "                    current_end = max(current_end, end)\n",
    "                else:\n",
    "                    merged.append((current_start, current_end))\n",
    "                    current_start, current_end = start, end\n",
    "            merged.append((current_start, current_end))\n",
    "\n",
    "        compressed_seq = []\n",
    "        chunk_map = []\n",
    "        last_end = 0\n",
    "        chunk_id = self.num_items + 1\n",
    "\n",
    "        for start, end in merged:\n",
    "            if last_end < start:\n",
    "                compressed_seq.append(chunk_id)\n",
    "                chunk_map.append((last_end, start))\n",
    "                chunk_id += 1\n",
    "            for i in range(start, end):\n",
    "                compressed_seq.append(seq[i])\n",
    "                chunk_map.append(i)\n",
    "            last_end = end\n",
    "\n",
    "        if last_end < len(seq):\n",
    "            compressed_seq.append(chunk_id)\n",
    "            chunk_map.append((last_end, len(seq)))\n",
    "\n",
    "        return compressed_seq, chunk_map\n",
    "\n",
    "# Model\n",
    "class SequentialRecommender(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim, num_heads, num_layers, dropout):\n",
    "        super(SequentialRecommender, self).__init__()\n",
    "        self.num_items = num_items\n",
    "        self.embedding = nn.Embedding(num_items + 10000, embedding_dim, padding_idx=0)  # Increased size\n",
    "        self.pos_encoding = nn.Parameter(self.create_pos_encoding(5000, embedding_dim))\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=embedding_dim,\n",
    "                nhead=num_heads,\n",
    "                dim_feedforward=embedding_dim * 4,\n",
    "                dropout=dropout,\n",
    "                batch_first=True\n",
    "            ),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(embedding_dim, num_items)\n",
    "\n",
    "    def create_pos_encoding(self, max_len, dim):\n",
    "        pe = torch.zeros(max_len, dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, dim, 2).float() * (-math.log(10000.0) / dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return pe\n",
    "\n",
    "    def compress_chunk(self, chunk, chunk_len):\n",
    "        chunk_emb = self.embedding(chunk)\n",
    "        chunk_mask = (chunk != 0).float().unsqueeze(-1)\n",
    "        chunk_emb = chunk_emb * chunk_mask\n",
    "        chunk_sum = chunk_emb.sum(dim=1)\n",
    "        chunk_count = chunk_mask.sum(dim=1).clamp(min=1)\n",
    "        return chunk_sum / chunk_count\n",
    "\n",
    "    def forward(self, batch):\n",
    "        seq = batch[\"seq\"].to(device)\n",
    "        compressed_seq = batch[\"compressed_seq\"].to(device)\n",
    "        mask_positions = batch[\"mask_positions\"].to(device)\n",
    "        chunk_map = batch[\"chunk_map\"]\n",
    "\n",
    "        batch_size, seq_len = compressed_seq.shape\n",
    "        embeddings = torch.zeros(batch_size, seq_len, embedding_dim).to(device)\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            for i in range(seq_len):\n",
    "                item = compressed_seq[b, i].item()\n",
    "                if item == self.num_items:  # [MASK]\n",
    "                    embeddings[b, i] = self.embedding(torch.tensor(self.num_items, device=device))\n",
    "                elif item > self.num_items:  # Chunk\n",
    "                    chunk_start, chunk_end = chunk_map[b][i]\n",
    "                    chunk = seq[b, chunk_start:chunk_end].unsqueeze(0)\n",
    "                    embeddings[b, i] = self.compress_chunk(chunk, chunk_end - chunk_start)[0]\n",
    "                else:\n",
    "                    embeddings[b, i] = self.embedding(compressed_seq[b, i])\n",
    "\n",
    "        embeddings = embeddings + self.pos_encoding[:seq_len].unsqueeze(0)\n",
    "        mask = (compressed_seq == 0).to(device)\n",
    "        output = self.transformer(embeddings, src_key_padding_mask=mask)\n",
    "\n",
    "        logits = []\n",
    "        for b in range(batch_size):\n",
    "            mask_pos = mask_positions[b][mask_positions[b] != 0]\n",
    "            if len(mask_pos) == 0:\n",
    "                continue\n",
    "            mask_output = output[b, mask_pos]\n",
    "            logit = self.fc(mask_output)\n",
    "            logits.append(logit)\n",
    "        if not logits:\n",
    "            return torch.tensor([]).to(device)\n",
    "        return torch.cat(logits, dim=0)\n",
    "\n",
    "    def predict(self, input_seq):\n",
    "        seq = input_seq[:, :max_seq_length]\n",
    "        seq = torch.where(seq >= self.num_items, torch.zeros_like(seq), seq)\n",
    "        next_pos = seq.shape[1]\n",
    "        seq = torch.cat([seq, torch.tensor([[self.num_items]], device=seq.device)], dim=1)\n",
    "\n",
    "        compressed_seqs = []\n",
    "        chunk_maps = []\n",
    "        for b in range(seq.shape[0]):\n",
    "            s = seq[b].cpu().numpy().tolist()\n",
    "            compressed, chunk_map = MovieLensDataset.compress_sequence(None, s, [next_pos])\n",
    "            compressed_seqs.append(compressed)\n",
    "            chunk_maps.append(chunk_map)\n",
    "\n",
    "        max_len = max(len(s) for s in compressed_seqs)\n",
    "        compressed_seq = torch.zeros(seq.shape[0], max_len, dtype=torch.long)\n",
    "        for b, s in enumerate(compressed_seqs):\n",
    "            compressed_seq[b, :len(s)] = torch.tensor(s)\n",
    "        compressed_seq = compressed_seq.to(device)\n",
    "\n",
    "        embeddings = torch.zeros(seq.shape[0], max_len, embedding_dim).to(device)\n",
    "        for b in range(seq.shape[0]):\n",
    "            for i in range(len(compressed_seqs[b])):\n",
    "                item = compressed_seq[b, i].item()\n",
    "                if item == self.num_items:\n",
    "                    embeddings[b, i] = self.embedding(torch.tensor(self.num_items, device=device))\n",
    "                elif item > self.num_items:\n",
    "                    chunk_start, chunk_end = chunk_maps[b][i]\n",
    "                    chunk = seq[b, chunk_start:chunk_end].unsqueeze(0)\n",
    "                    embeddings[b, i] = self.compress_chunk(chunk, chunk_end - chunk_start)[0]\n",
    "                else:\n",
    "                    embeddings[b, i] = self.embedding(compressed_seq[b, i])\n",
    "\n",
    "        embeddings = embeddings + self.pos_encoding[:max_len].unsqueeze(0)\n",
    "        mask = (compressed_seq == 0).to(device)\n",
    "        output = self.transformer(embeddings, src_key_padding_mask=mask)\n",
    "        logits = self.fc(output[:, -1])\n",
    "        return logits\n",
    "\n",
    "# Evaluation\n",
    "def evaluate(model, user_dict, num_items, max_seq_length, device):\n",
    "    model.eval()\n",
    "    NDCG, HR, valid_users = 0.0, 0.0, 0\n",
    "\n",
    "    for user, items in user_dict.items():\n",
    "        if len(items) < 2:\n",
    "            continue\n",
    "\n",
    "        seq = items[:max_seq_length]\n",
    "        input_seq = torch.tensor(seq[:-1], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        target = seq[-1]\n",
    "        candidates = [target] + random.sample(list(set(range(1, num_items + 1)) - set(items)), num_negatives)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model.predict(input_seq)\n",
    "            scores = logits[0, candidates]\n",
    "            ranked = torch.argsort(scores, descending=True).cpu().numpy()\n",
    "            rank = np.where(ranked == 0)[0][0] + 1\n",
    "\n",
    "        valid_users += 1\n",
    "        HR += int(rank <= 10)\n",
    "        NDCG += 1 / np.log2(rank + 1) if rank <= 10 else 0\n",
    "\n",
    "        if valid_users % 100 == 0:\n",
    "            print(f\"Validated users: {valid_users}, HR@10: {HR / valid_users:.4f}, NDCG@10: {NDCG / valid_users:.4f}\")\n",
    "\n",
    "    print(f\"Final HR@10: {HR / valid_users:.4f}, NDCG@10: {NDCG / valid_users:.4f}\")\n",
    "    return HR / valid_users, NDCG / valid_users\n",
    "\n",
    "# Load dataset\n",
    "def load_movielens(file_path):\n",
    "    user_dict = defaultdict(list)\n",
    "    item_set = set()\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            user_id, item_id = map(int, line.strip().split())\n",
    "            user_dict[user_id].append(item_id)\n",
    "            item_set.add(item_id)\n",
    "    num_items = max(item_set)\n",
    "    return user_dict, num_items\n",
    "\n",
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"data/ml-1m.txt\"\n",
    "    user_dict, num_items = load_movielens(file_path)\n",
    "    print(f\"Number of users: {len(user_dict)}, Number of items: {num_items}\")\n",
    "\n",
    "    dataset = MovieLensDataset(user_dict, num_items, max_seq_length, window_size, mask_prob)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "    model = SequentialRecommender(num_items, embedding_dim, num_heads, num_layers, dropout).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    \n",
    "    # length of dataloader\n",
    "    dataloader_length = len(dataloader)\n",
    "    print(f\"Length of dataloader: {dataloader_length}\")\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            seq = batch[\"seq\"].to(device)\n",
    "            logits = model(batch)\n",
    "            if logits.numel() == 0:\n",
    "                continue\n",
    "\n",
    "            mask_positions = batch[\"mask_positions\"].to(device)\n",
    "            targets = []\n",
    "            for b in range(seq.shape[0]):\n",
    "                mask_pos = mask_positions[b][mask_positions[b] != 0]\n",
    "                if len(mask_pos) > 0:\n",
    "                    valid_targets = seq[b, mask_pos]\n",
    "                    # Filter out invalid targets (e.g., masks or padding)\n",
    "                    valid_targets = valid_targets[valid_targets != num_items]  # Exclude [MASK]\n",
    "                    valid_targets = valid_targets[valid_targets != 0]  # Exclude padding\n",
    "                    if len(valid_targets) > 0:\n",
    "                        targets.append(valid_targets)\n",
    "            if not targets:\n",
    "                continue\n",
    "            targets = torch.cat(targets).to(device)\n",
    "\n",
    "            # Ensure logits and targets align\n",
    "            if logits.shape[0] != targets.shape[0]:\n",
    "                print(f\"Batch {batch_idx}: Logits shape {logits.shape}, Targets shape {targets.shape}\")\n",
    "                continue\n",
    "\n",
    "            loss = criterion(logits, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            print(f\"Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
    "            \n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader):.4f}\")\n",
    "\n",
    "    evaluate(model, user_dict, num_items, max_seq_length, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3f508d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 234\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    233\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/ml-1m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 234\u001b[0m     user_dict, num_items \u001b[38;5;241m=\u001b[39m \u001b[43mload_movielens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of users: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(user_dict)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Number of items: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_items\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    237\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m MovieLensDataset(user_dict, num_items, max_seq_length)\n",
      "Cell \u001b[0;32mIn[1], line 225\u001b[0m, in \u001b[0;36mload_movielens\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[0;32m--> 225\u001b[0m         user_id, item_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmap\u001b[39;49m(\u001b[38;5;28mint\u001b[39m, line\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit())\n\u001b[1;32m    226\u001b[0m         user_dict[user_id]\u001b[38;5;241m.\u001b[39mappend(item_id)\n\u001b[1;32m    227\u001b[0m         item_set\u001b[38;5;241m.\u001b[39madd(item_id)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 128\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "dropout = 0.1\n",
    "max_seq_length = 200\n",
    "window_size = 50\n",
    "chunk_size = 100\n",
    "batch_size = 128\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "mask_prob = 0.15\n",
    "num_masks_per_batch = 3\n",
    "num_negatives = 99\n",
    "\n",
    "# Custom collation function\n",
    "def custom_collate_fn(batch):\n",
    "    seqs = torch.stack([item[\"seq\"] for item in batch])\n",
    "    return {\"seq\": seqs}\n",
    "\n",
    "# Dataset class\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, user_dict, num_items, max_seq_length):\n",
    "        self.user_dict = user_dict\n",
    "        self.num_items = num_items\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.users = list(user_dict.keys())\n",
    "        self.precomputed = self.precompute_sequences()\n",
    "\n",
    "    def precompute_sequences(self):\n",
    "        precomputed = {}\n",
    "        for user in self.users:\n",
    "            seq = self.user_dict[user][:self.max_seq_length]\n",
    "            if len(seq) < 2:\n",
    "                seq = [0] * self.max_seq_length\n",
    "            else:\n",
    "                seq = seq + [0] * (self.max_seq_length - len(seq)) if len(seq) < self.max_seq_length else seq\n",
    "            precomputed[user] = torch.tensor(seq, dtype=torch.long)\n",
    "        return precomputed\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user = self.users[idx]\n",
    "        seq = self.precomputed[user].clone()\n",
    "        return {\"seq\": seq}\n",
    "\n",
    "# Model\n",
    "class SequentialRecommender(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim, num_heads, num_layers, dropout, window_size):\n",
    "        super(SequentialRecommender, self).__init__()\n",
    "        self.num_items = num_items\n",
    "        self.window_size = window_size\n",
    "        self.embedding = nn.Embedding(num_items + 10000, embedding_dim, padding_idx=0)\n",
    "        self.pos_encoding = nn.Parameter(self.create_pos_encoding(5000, embedding_dim))\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=embedding_dim,\n",
    "                nhead=num_heads,\n",
    "                dim_feedforward=embedding_dim * 4,\n",
    "                dropout=dropout,\n",
    "                batch_first=True\n",
    "            ),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(embedding_dim, num_items)\n",
    "\n",
    "    def create_pos_encoding(self, max_len, dim):\n",
    "        pe = torch.zeros(max_len, dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, dim, 2).float() * (-math.log(10000.0) / dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return pe\n",
    "\n",
    "    def compress_sequence(self, seq, mask_positions):\n",
    "        batch_size, seq_len = seq.shape\n",
    "        windows = []\n",
    "        for pos in mask_positions:\n",
    "            start = max(0, pos - self.window_size)\n",
    "            end = min(seq_len, pos + self.window_size + 1)\n",
    "            windows.append((start, end))\n",
    "\n",
    "        merged = []\n",
    "        if windows:\n",
    "            current_start, current_end = windows[0]\n",
    "            for start, end in windows[1:]:\n",
    "                if start <= current_end:\n",
    "                    current_end = max(current_end, end)\n",
    "                else:\n",
    "                    merged.append((current_start, current_end))\n",
    "                    current_start, current_end = start, end\n",
    "            merged.append((current_start, current_end))\n",
    "\n",
    "        total_len = 0\n",
    "        last_end = 0\n",
    "        for start, end in merged:\n",
    "            if last_end < start:\n",
    "                total_len += 1\n",
    "            total_len += end - start\n",
    "            last_end = end\n",
    "        if last_end < seq_len:\n",
    "            total_len += 1\n",
    "\n",
    "        compressed_seq = torch.zeros(batch_size, total_len, dtype=torch.long, device=seq.device)\n",
    "        chunk_map = [[] for _ in range(batch_size)]\n",
    "        mask_indices = []\n",
    "        chunk_id = self.num_items + 1\n",
    "        pos = 0\n",
    "\n",
    "        last_end = 0\n",
    "        for start, end in merged:\n",
    "            if last_end < start:\n",
    "                compressed_seq[:, pos] = chunk_id\n",
    "                for b in range(batch_size):\n",
    "                    chunk_map[b].append((last_end, start))\n",
    "                chunk_id += 1\n",
    "                pos += 1\n",
    "            window_len = end - start\n",
    "            compressed_seq[:, pos:pos + window_len] = seq[:, start:end].clone()\n",
    "            for mp in mask_positions:\n",
    "                if start <= mp < end and pos + (mp - start) not in mask_indices:  # Avoid duplicates\n",
    "                    mask_indices.append(pos + (mp - start))\n",
    "            for b in range(batch_size):\n",
    "                chunk_map[b].extend(list(range(start, end)))\n",
    "            pos += window_len\n",
    "            last_end = end\n",
    "\n",
    "        if last_end < seq_len:\n",
    "            compressed_seq[:, pos] = chunk_id\n",
    "            for b in range(batch_size):\n",
    "                chunk_map[b].append((last_end, seq_len))\n",
    "\n",
    "        return compressed_seq, chunk_map, torch.tensor(mask_indices, device=seq.device)\n",
    "\n",
    "    def forward(self, seq, mask_positions):\n",
    "        batch_size, seq_len = seq.shape\n",
    "        masked_seq = seq.clone()\n",
    "        masked_seq[torch.arange(batch_size).unsqueeze(1), mask_positions] = self.num_items\n",
    "\n",
    "        compressed_seq, chunk_map, mask_indices = self.compress_sequence(masked_seq, mask_positions)\n",
    "        batch_size, comp_len = compressed_seq.shape\n",
    "        embeddings = self.embedding(compressed_seq)\n",
    "\n",
    "        is_chunk = (compressed_seq > self.num_items)\n",
    "        chunk_indices = torch.where(is_chunk)\n",
    "        if chunk_indices[0].numel() > 0:\n",
    "            chunk_embeddings = []\n",
    "            for b, i in zip(chunk_indices[0], chunk_indices[1]):\n",
    "                chunk_start, chunk_end = chunk_map[b][i]\n",
    "                chunk = seq[b, chunk_start:chunk_end].unsqueeze(0)\n",
    "                chunk_emb = self.embedding(chunk)\n",
    "                chunk_mask = (chunk != 0).float().unsqueeze(-1)\n",
    "                chunk_sum = (chunk_emb * chunk_mask).sum(dim=1)\n",
    "                chunk_count = chunk_mask.sum(dim=1).clamp(min=1)\n",
    "                chunk_embeddings.append(chunk_sum / chunk_count)\n",
    "            embeddings[chunk_indices] = torch.cat(chunk_embeddings)\n",
    "\n",
    "        embeddings = embeddings + self.pos_encoding[:comp_len].unsqueeze(0)\n",
    "        mask = (compressed_seq == 0).to(device)\n",
    "        output = self.transformer(embeddings, src_key_padding_mask=mask)\n",
    "\n",
    "        mask_output = output[torch.arange(batch_size).unsqueeze(1), mask_indices]\n",
    "        logits = self.fc(mask_output)  # Shape: (batch_size, num_masks, num_items)\n",
    "        return logits, mask_indices  # Return mask_indices for alignment\n",
    "\n",
    "    def predict(self, input_seq):\n",
    "        seq = input_seq[:, :max_seq_length]\n",
    "        seq = torch.where(seq >= self.num_items, torch.zeros_like(seq), seq)\n",
    "        next_pos = seq.shape[1]\n",
    "        seq = torch.cat([seq, torch.full((seq.shape[0], 1), self.num_items, device=seq.device)], dim=1)\n",
    "        mask_positions = torch.tensor([next_pos], device=seq.device)\n",
    "        logits, _ = self.forward(seq, mask_positions)\n",
    "        return logits\n",
    "\n",
    "# Evaluation\n",
    "def evaluate(model, user_dict, num_items, max_seq_length, device):\n",
    "    model.eval()\n",
    "    NDCG, HR, valid_users = 0.0, 0.0, 0\n",
    "\n",
    "    for user, items in user_dict.items():\n",
    "        if len(items) < 2:\n",
    "            continue\n",
    "\n",
    "        seq = items[:max_seq_length]\n",
    "        input_seq = torch.tensor(seq[:-1], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        target = seq[-1]\n",
    "        candidates = [target] + random.sample(list(set(range(1, num_items + 1)) - set(items)), num_negatives)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model.predict(input_seq)\n",
    "            scores = logits[0, 0, candidates]  # Single mask in predict\n",
    "            ranked = torch.argsort(scores, descending=True).cpu().numpy()\n",
    "            rank = np.where(ranked == 0)[0][0] + 1\n",
    "\n",
    "        valid_users += 1\n",
    "        HR += int(rank <= 10)\n",
    "        NDCG += 1 / np.log2(rank + 1) if rank <= 10 else 0\n",
    "\n",
    "        if valid_users % 100 == 0:\n",
    "            print(f\"Validated users: {valid_users}, HR@10: {HR / valid_users:.4f}, NDCG@10: {NDCG / valid_users:.4f}\")\n",
    "\n",
    "    print(f\"Final HR@10: {HR / valid_users:.4f}, NDCG@10: {NDCG / valid_users:.4f}\")\n",
    "    return HR / valid_users, NDCG / valid_users\n",
    "\n",
    "# Load dataset\n",
    "def load_movielens(file_path):\n",
    "    user_dict = defaultdict(list)\n",
    "    item_set = set()\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            user_id, item_id = map(int, line.strip().split())\n",
    "            user_dict[user_id].append(item_id)\n",
    "            item_set.add(item_id)\n",
    "    num_items = max(item_set)\n",
    "    return user_dict, num_items\n",
    "\n",
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"data/ml-1m.txt\"\n",
    "    user_dict, num_items = load_movielens(file_path)\n",
    "    print(f\"Number of users: {len(user_dict)}, Number of items: {num_items}\")\n",
    "\n",
    "    dataset = MovieLensDataset(user_dict, num_items, max_seq_length)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "    model = SequentialRecommender(num_items, embedding_dim, num_heads, num_layers, dropout, window_size).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "    print(f\"Length of dataloader: {len(dataloader)}\")\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            seq = batch[\"seq\"].to(device)\n",
    "            batch_size = seq.shape[0]\n",
    "            valid_positions = (seq != 0).sum(dim=0).nonzero(as_tuple=True)[0]\n",
    "            if len(valid_positions) < num_masks_per_batch:\n",
    "                continue\n",
    "            mask_positions = random.sample(valid_positions.tolist(), num_masks_per_batch)\n",
    "            mask_positions = torch.tensor(mask_positions, device=device)\n",
    "\n",
    "            logits, mask_indices = model(seq, mask_positions)  # Shape: (batch_size, num_masks, num_items)\n",
    "            if logits.numel() == 0:\n",
    "                continue\n",
    "\n",
    "            targets = seq[torch.arange(batch_size).unsqueeze(1), mask_positions]  # Shape: (batch_size, num_masks)\n",
    "            valid_mask = (targets != num_items) & (targets != 0)  # Shape: (batch_size, num_masks)\n",
    "\n",
    "            # Reshape based on actual number of masks (mask_indices)\n",
    "            num_masks = mask_indices.shape[0]\n",
    "            logits = logits.view(batch_size * num_masks, num_items)  # Shape: (batch_size * num_masks, num_items)\n",
    "            targets = targets.view(batch_size * num_masks_per_batch)  # Shape: (batch_size * num_masks)\n",
    "            valid_mask = valid_mask.view(batch_size * num_masks_per_batch)\n",
    "\n",
    "            # Filter only valid predictions\n",
    "            targets = targets[valid_mask]\n",
    "            logits = logits[:len(targets)]  # Adjust logits to match targets length\n",
    "\n",
    "            if logits.shape[0] != targets.shape[0] or targets.numel() == 0:\n",
    "                continue\n",
    "\n",
    "            loss = criterion(logits, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader):.4f}\")\n",
    "\n",
    "    evaluate(model, user_dict, num_items, max_seq_length, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decc5906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 6040, Number of items: 3416\n",
      "Length of dataloader: 12\n",
      "Epoch 1, Loss: 7.9794\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/home/gnaneswaras/.local/lib/python3.8/site-packages/torch/nn/modules/transformer.py:409: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, HR@10: 0.3772, NDCG@10: 0.1947\n",
      "Epoch 2, Loss: 4.4396\n",
      "Epoch 3, Loss: 7.4858\n",
      "Epoch 4, Loss: 6.2678\n",
      "Epoch 5, Loss: 7.4478\n",
      "Epoch 6, Loss: 6.1570\n",
      "Epoch 7, Loss: 4.9915\n",
      "Epoch 8, Loss: 6.8161\n",
      "Epoch 9, Loss: 5.5573\n",
      "Epoch 10, Loss: 6.7708\n",
      "Epoch 11, Loss: 6.1484\n",
      "Evaluating...\n",
      "Epoch 11, HR@10: 0.4550, NDCG@10: 0.2506\n",
      "Epoch 12, Loss: 6.1409\n",
      "Epoch 13, Loss: 5.5551\n",
      "Epoch 14, Loss: 6.7167\n",
      "Epoch 15, Loss: 5.5659\n",
      "Epoch 16, Loss: 5.5613\n",
      "Epoch 17, Loss: 6.1731\n",
      "Epoch 18, Loss: 5.5308\n",
      "Epoch 19, Loss: 6.1632\n",
      "Epoch 20, Loss: 5.5201\n",
      "Epoch 21, Loss: 6.7383\n",
      "Evaluating...\n",
      "Epoch 21, HR@10: 0.4616, NDCG@10: 0.2519\n",
      "Epoch 22, Loss: 4.9680\n",
      "Epoch 23, Loss: 6.1492\n",
      "Epoch 24, Loss: 6.1620\n",
      "Epoch 25, Loss: 4.9555\n",
      "Epoch 26, Loss: 6.7825\n",
      "Epoch 27, Loss: 7.4052\n",
      "Epoch 28, Loss: 6.1605\n",
      "Epoch 29, Loss: 6.1544\n",
      "Epoch 30, Loss: 6.1566\n",
      "Epoch 31, Loss: 6.7728\n",
      "Evaluating...\n",
      "Epoch 31, HR@10: 0.4606, NDCG@10: 0.2514\n",
      "Epoch 32, Loss: 5.5573\n",
      "Epoch 33, Loss: 6.7396\n",
      "Epoch 34, Loss: 5.5475\n",
      "Epoch 35, Loss: 5.5806\n",
      "Epoch 36, Loss: 6.1490\n",
      "Epoch 37, Loss: 7.3769\n",
      "Epoch 38, Loss: 4.2723\n",
      "Epoch 39, Loss: 4.9624\n",
      "Epoch 40, Loss: 6.7684\n",
      "Epoch 41, Loss: 6.7327\n",
      "Evaluating...\n",
      "Epoch 41, HR@10: 0.4624, NDCG@10: 0.2515\n",
      "Epoch 42, Loss: 6.7525\n",
      "Epoch 43, Loss: 5.5503\n",
      "Epoch 44, Loss: 6.7273\n",
      "Epoch 45, Loss: 5.5730\n",
      "Epoch 46, Loss: 5.5188\n",
      "Epoch 47, Loss: 7.4097\n",
      "Epoch 48, Loss: 6.7303\n",
      "Epoch 49, Loss: 6.1050\n",
      "Epoch 50, Loss: 6.1404\n",
      "Epoch 51, Loss: 6.7070\n",
      "Evaluating...\n",
      "Epoch 51, HR@10: 0.4732, NDCG@10: 0.2578\n",
      "Epoch 52, Loss: 5.5349\n",
      "Epoch 53, Loss: 4.3056\n",
      "Epoch 54, Loss: 6.7949\n",
      "Epoch 55, Loss: 6.8035\n",
      "Epoch 56, Loss: 6.1239\n",
      "Epoch 57, Loss: 6.6927\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 128\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "dropout = 0.1\n",
    "max_seq_length = 200\n",
    "window_size = 50\n",
    "chunk_size = 100\n",
    "batch_size = 512\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "mask_prob = 0.15\n",
    "num_masks_per_batch = 3\n",
    "num_negatives = 99\n",
    "\n",
    "# Custom collation function\n",
    "def custom_collate_fn(batch):\n",
    "    seqs = torch.stack([item[\"seq\"] for item in batch])\n",
    "    return {\"seq\": seqs}\n",
    "\n",
    "# Dataset class\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, user_dict, num_items, max_seq_length):\n",
    "        self.user_dict = user_dict\n",
    "        self.num_items = num_items\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.users = list(user_dict.keys())\n",
    "        self.precomputed = self.precompute_sequences()\n",
    "\n",
    "    def precompute_sequences(self):\n",
    "        precomputed = {}\n",
    "        for user in self.users:\n",
    "            seq = self.user_dict[user][:self.max_seq_length]\n",
    "            if len(seq) < 2:\n",
    "                seq = [0] * self.max_seq_length\n",
    "            else:\n",
    "                seq = seq + [0] * (self.max_seq_length - len(seq)) if len(seq) < self.max_seq_length else seq\n",
    "            precomputed[user] = torch.tensor(seq, dtype=torch.long)\n",
    "        return precomputed\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user = self.users[idx]\n",
    "        seq = self.precomputed[user].clone()\n",
    "        return {\"seq\": seq}\n",
    "\n",
    "# Model\n",
    "class SequentialRecommender(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim, num_heads, num_layers, dropout, window_size):\n",
    "        super(SequentialRecommender, self).__init__()\n",
    "        self.num_items = num_items\n",
    "        self.window_size = window_size\n",
    "        self.embedding = nn.Embedding(num_items + 10000, embedding_dim, padding_idx=0)\n",
    "        self.pos_encoding = nn.Parameter(self.create_pos_encoding(5000, embedding_dim))\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=embedding_dim,\n",
    "                nhead=num_heads,\n",
    "                dim_feedforward=embedding_dim * 4,\n",
    "                dropout=dropout,\n",
    "                batch_first=True\n",
    "            ),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(embedding_dim, num_items)\n",
    "\n",
    "    def create_pos_encoding(self, max_len, dim):\n",
    "        pe = torch.zeros(max_len, dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, dim, 2).float() * (-math.log(10000.0) / dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return pe\n",
    "\n",
    "    def compress_sequence(self, seq, mask_positions):\n",
    "        batch_size, seq_len = seq.shape\n",
    "        windows = []\n",
    "        for pos in mask_positions:\n",
    "            start = max(0, pos - self.window_size)\n",
    "            end = min(seq_len, pos + self.window_size + 1)\n",
    "            windows.append((start, end))\n",
    "\n",
    "        merged = []\n",
    "        if windows:\n",
    "            current_start, current_end = windows[0]\n",
    "            for start, end in windows[1:]:\n",
    "                if start <= current_end:\n",
    "                    current_end = max(current_end, end)\n",
    "                else:\n",
    "                    merged.append((current_start, current_end))\n",
    "                    current_start, current_end = start, end\n",
    "            merged.append((current_start, current_end))\n",
    "\n",
    "        total_len = 0\n",
    "        last_end = 0\n",
    "        for start, end in merged:\n",
    "            if last_end < start:\n",
    "                total_len += 1\n",
    "            total_len += end - start\n",
    "            last_end = end\n",
    "        if last_end < seq_len:\n",
    "            total_len += 1\n",
    "\n",
    "        compressed_seq = torch.zeros(batch_size, total_len, dtype=torch.long, device=seq.device)\n",
    "        chunk_map = [[] for _ in range(batch_size)]\n",
    "        mask_indices = []\n",
    "        chunk_id = self.num_items + 1\n",
    "        pos = 0\n",
    "\n",
    "        last_end = 0\n",
    "        for start, end in merged:\n",
    "            if last_end < start:\n",
    "                compressed_seq[:, pos] = chunk_id\n",
    "                for b in range(batch_size):\n",
    "                    chunk_map[b].append((last_end, start))\n",
    "                chunk_id += 1\n",
    "                pos += 1\n",
    "            window_len = end - start\n",
    "            compressed_seq[:, pos:pos + window_len] = seq[:, start:end].clone()\n",
    "            for mp in mask_positions:\n",
    "                if start <= mp < end and pos + (mp - start) not in mask_indices:\n",
    "                    mask_indices.append(pos + (mp - start))\n",
    "            for b in range(batch_size):\n",
    "                chunk_map[b].extend(list(range(start, end)))\n",
    "            pos += window_len\n",
    "            last_end = end\n",
    "\n",
    "        if last_end < seq_len:\n",
    "            compressed_seq[:, pos] = chunk_id\n",
    "            for b in range(batch_size):\n",
    "                chunk_map[b].append((last_end, seq_len))\n",
    "\n",
    "        return compressed_seq, chunk_map, torch.tensor(mask_indices, device=seq.device)\n",
    "\n",
    "    def forward(self, seq, mask_positions, is_predict=False):\n",
    "        batch_size, seq_len = seq.shape\n",
    "        masked_seq = seq.clone()\n",
    "        masked_seq[torch.arange(batch_size).unsqueeze(1), mask_positions] = self.num_items\n",
    "\n",
    "        compressed_seq, chunk_map, mask_indices = self.compress_sequence(masked_seq, mask_positions)\n",
    "        batch_size, comp_len = compressed_seq.shape\n",
    "        embeddings = self.embedding(compressed_seq)\n",
    "\n",
    "        is_chunk = (compressed_seq > self.num_items)\n",
    "        chunk_indices = torch.where(is_chunk)\n",
    "        if chunk_indices[0].numel() > 0:\n",
    "            chunk_embeddings = []\n",
    "            for b, i in zip(chunk_indices[0], chunk_indices[1]):\n",
    "                chunk_start, chunk_end = chunk_map[b][i]\n",
    "                chunk = seq[b, chunk_start:chunk_end].unsqueeze(0)\n",
    "                chunk_emb = self.embedding(chunk)\n",
    "                chunk_mask = (chunk != 0).float().unsqueeze(-1)\n",
    "                chunk_sum = (chunk_emb * chunk_mask).sum(dim=1)\n",
    "                chunk_count = chunk_mask.sum(dim=1).clamp(min=1)\n",
    "                chunk_embeddings.append(chunk_sum / chunk_count)\n",
    "            embeddings[chunk_indices] = torch.cat(chunk_embeddings)\n",
    "\n",
    "        embeddings = embeddings + self.pos_encoding[:comp_len].unsqueeze(0)\n",
    "        mask = (compressed_seq == 0).to(device)\n",
    "        output = self.transformer(embeddings, src_key_padding_mask=mask)\n",
    "\n",
    "        mask_output = output[torch.arange(batch_size).unsqueeze(1), mask_indices]\n",
    "        logits = self.fc(mask_output)  # Shape: (batch_size, num_masks, num_items)\n",
    "        \n",
    "        # For predict, ensure only the last mask is used\n",
    "        if is_predict and len(mask_indices) > 1:\n",
    "            mask_output = mask_output[:, -1:, :]  # Take only the last mask\n",
    "            logits = self.fc(mask_output)         # Shape: (batch_size, 1, num_items)\n",
    "        \n",
    "        return logits, mask_indices\n",
    "\n",
    "    def predict(self, input_seq):\n",
    "        seq = input_seq[:, :max_seq_length]\n",
    "        seq = torch.where(seq >= self.num_items, torch.zeros_like(seq), seq)\n",
    "        next_pos = seq.shape[1]\n",
    "        seq = torch.cat([seq, torch.full((seq.shape[0], 1), self.num_items, device=seq.device)], dim=1)\n",
    "        mask_positions = torch.tensor([next_pos], device=seq.device)\n",
    "        logits, _ = self.forward(seq, mask_positions, is_predict=True)\n",
    "        return logits\n",
    "\n",
    "# Evaluation\n",
    "def evaluate(model, user_dict, num_items, max_seq_length, device):\n",
    "    model.eval()\n",
    "    NDCG, HR, valid_users = 0.0, 0.0, 0\n",
    "\n",
    "    for user, items in user_dict.items():\n",
    "        if len(items) < 2:\n",
    "            continue\n",
    "\n",
    "        seq = items[:max_seq_length]\n",
    "        input_seq = torch.tensor(seq[:-1], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        target = seq[-1]\n",
    "        candidates = [target] + random.sample(list(set(range(1, num_items)) - set(items)), num_negatives)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model.predict(input_seq)\n",
    "            scores = logits[0, 0, candidates]  # Single mask in predict\n",
    "            \n",
    "            ranked = torch.argsort(scores, descending=True).cpu().numpy()\n",
    "            rank = np.where(ranked == 0)[0][0] + 1\n",
    "\n",
    "        valid_users += 1\n",
    "        HR += int(rank <= 10)\n",
    "        NDCG += 1 / np.log2(rank + 1) if rank <= 10 else 0\n",
    "\n",
    "        # if valid_users % 100 == 0:\n",
    "        #     print(f\"Validated users: {valid_users}, HR@10: {HR / valid_users:.4f}, NDCG@10: {NDCG / valid_users:.4f}\")\n",
    "\n",
    "    # print(f\"Final HR@10: {HR / valid_users:.4f}, NDCG@10: {NDCG / valid_users:.4f}\")\n",
    "    return HR / valid_users, NDCG / valid_users\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "def load_movielens(file_path):\n",
    "    user_dict = defaultdict(list)\n",
    "    item_set = set()\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            user_id, item_id = map(int, line.strip().split())\n",
    "            user_dict[user_id].append(item_id)\n",
    "            item_set.add(item_id)\n",
    "    num_items = max(item_set)\n",
    "    return user_dict, num_items\n",
    "\n",
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"data/ml-1m.txt\"\n",
    "    user_dict, num_items = load_movielens(file_path)\n",
    "    print(f\"Number of users: {len(user_dict)}, Number of items: {num_items}\")\n",
    "\n",
    "    dataset = MovieLensDataset(user_dict, num_items, max_seq_length)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "    model = SequentialRecommender(num_items, embedding_dim, num_heads, num_layers, dropout, window_size).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "    print(f\"Length of dataloader: {len(dataloader)}\")\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            seq = batch[\"seq\"].to(device)\n",
    "            batch_size = seq.shape[0]\n",
    "            valid_positions = (seq != 0).sum(dim=0).nonzero(as_tuple=True)[0]\n",
    "            if len(valid_positions) < num_masks_per_batch:\n",
    "                continue\n",
    "            mask_positions = random.sample(valid_positions.tolist(), num_masks_per_batch)\n",
    "            mask_positions = torch.tensor(mask_positions, device=device)\n",
    "\n",
    "            logits, mask_indices = model(seq, mask_positions)  # Shape: (batch_size, num_masks, num_items)\n",
    "            if logits.numel() == 0:\n",
    "                continue\n",
    "\n",
    "            targets = seq[torch.arange(batch_size).unsqueeze(1), mask_positions]  # Shape: (batch_size, num_masks_per_batch)\n",
    "            valid_mask = (targets != num_items) & (targets != 0)  # Shape: (batch_size, num_masks_per_batch)\n",
    "\n",
    "            num_masks = mask_indices.shape[0]\n",
    "            logits = logits.view(batch_size * num_masks, num_items)  # Shape: (batch_size * num_masks, num_items)\n",
    "            targets = targets.view(batch_size * num_masks_per_batch)  # Shape: (batch_size * num_masks_per_batch)\n",
    "            valid_mask = valid_mask.view(batch_size * num_masks_per_batch)\n",
    "\n",
    "            targets = targets[valid_mask]\n",
    "            logits = logits[:targets.shape[0]]  # Align with filtered targets\n",
    "\n",
    "            if logits.shape[0] != targets.shape[0] or targets.numel() == 0:\n",
    "                continue\n",
    "\n",
    "            loss = criterion(logits, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # if batch_idx % 10 == 0:\n",
    "            #     print(f\"Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader):.4f}\")\n",
    "        if epoch % 10 == 0:\n",
    "            # Evaluate every 10 epochs\n",
    "            print(\"Evaluating...\")\n",
    "            HR, NDCG = evaluate(model, user_dict, num_items, max_seq_length, device)\n",
    "            print(f\"Epoch {epoch+1}, HR@10: {HR:.4f}, NDCG@10: {NDCG:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580298b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
