Arguments:
backbone qmamba
batch_size 16
dataset ml-1m
device cuda:3
dropout_rate 0.5
eval_neg_sample 100
hidden_units 32
inference_only False
l2_emb 0.0
lr 0.0005
maxlen 204
name mamba
num_blocks 2
num_epochs 500
num_heads 1
state_dict_path None
train_dir tracks256_default/

user_count: 6040
item count: 3416
6040
average sequence length: 163.50
Quantized Mamba Rec device:  cuda:3
parameters_count: 130402
loss in epoch 1 iteration 376: 1.209571361541748
loss in epoch 2 iteration 376: 1.0504136085510254
