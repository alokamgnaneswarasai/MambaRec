Arguments:
backbone jamba
batch_size 16
dataset ml-1m
device cuda:3
dropout_rate 0.5
eval_neg_sample 100
hidden_units 50
inference_only False
l2_emb 0.0
lr 0.0005
maxlen 250
name mamba
num_blocks 2
num_epochs 501
num_heads 1
state_dict_path None
train_dir tracks256_default/

user_count: 6040
item count: 3416
6040
average sequence length: 163.50
parameters_count: 693100
loss in epoch 1 iteration 376: 0.9203499555587769
loss in epoch 2 iteration 376: 0.8553777933120728
loss in epoch 3 iteration 376: 0.6881945133209229
loss in epoch 4 iteration 376: 0.622265100479126
loss in epoch 5 iteration 376: 0.4460793137550354
Evaluatingepoch:5, time: 174472.800970(s), valid (NDCG@5: 0.2537, HR@5: 0.3750, NDCG@10: 0.3070, HR@10: 0.5397, NDCG@20: 0.3506, HR@20: 0.7126), test (NDCG@5: 0.2460, HR@5: 0.3639, NDCG@10: 0.2982, HR@10: 0.5257, NDCG@20: 0.3410, HR@20: 0.6950)
loss in epoch 6 iteration 376: 0.3359874188899994
loss in epoch 7 iteration 376: 0.31290289759635925
loss in epoch 8 iteration 376: 0.20793673396110535
loss in epoch 9 iteration 376: 0.21714842319488525
loss in epoch 10 iteration 376: 0.20053794980049133
Evaluating